{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\ucc57\ubd07 \ud29c\ud1a0\ub9ac\uc5bc\n================\n**Author:** `Matthew Inkawhich <https://github.com/MatthewInkawhich>`_\n  **\ubc88\uc5ed**: `\uae40\uc9c4\ud604 <https://github.com/lewha0>`_\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \uc21c\ud658(recurrent) \uc2dc\ud000\uc2a4 \ud22c \uc2dc\ud000\uc2a4(sequence-to-sequence)\n\ubaa8\ub378\uc758 \uc7ac\ubbf8\uc788\uace0 \ud765\ubbf8\ub85c\uc6b4 \uc0ac\uc6a9 \uc608\ub97c \uc0b4\ud3b4\ubcf4\ub824 \ud569\ub2c8\ub2e4. \uac04\ub2e8\ud55c \ucc57\ubd07\uc744 \ud559\uc2b5\ud574\n\ubcfc \ud150\ub370, \uc0ac\uc6a9\ud560 \ub370\uc774\ud130\ub294 \uc601\ud654 \ub300\ubcf8\uc73c\ub85c \uad6c\uc131\ub41c `Cornell Movie-Dialogs(\ucf54\ub12c\n\ub300\ud559\uad50\uc758 \uc601\ud654 \uc18d \ub300\ud654 \ub9d0\ubb49\uce58 \ub370\uc774\ud130\n<https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__\n\uc785\ub2c8\ub2e4.\n\n\ub300\ud654\ud615 \ubaa8\ub378\uc740 \ub9ce\uc740 \uc0ac\ub78c\ub4e4\uc774 \uad00\uc2ec\uc744 \uac16\ub294 \uc778\uacf5\uc9c0\ub2a5 \ubd84\uc57c\uc758 \uc5f0\uad6c \uc8fc\uc81c\uc785\ub2c8\ub2e4.\n\uace0\uac1d \uc11c\ube44\uc2a4\uc640 \uad00\ub828\ub41c \ud65c\uc6a9, \uc628\ub77c\uc778 \ud5ec\ud504\ub370\uc2a4\ud06c \ub4f1 \uc5ec\ub7ec \uc0c1\ud669\uc5d0\uc11c \ucc57\ubd07\uc744\n\ud65c\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub9ce\uc740 \ucc57\ubd07\uc774 \uac80\uc0c9 \uae30\ubc18(retrieval-based) \ubaa8\ub378\uc744\n\uc0ac\uc6a9\ud558\ub294\ub370, \uc774\ub294 \ud2b9\uc815\ud55c \ud615\uc2dd\uc744 \uac16\ucd98 \uc9c8\ubb38\uc5d0 \ub300\ud574 \ubbf8\ub9ac \uc815\ud574\uc9c4 \ubc18\uc751\uc744\n\ucd9c\ub825\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4. \ubd84\uc57c\ub97c \ud2b9\uc815 \ud68c\uc0ac\uc758 IT \ud5ec\ud504\ub370\uc2a4\ud06c\ucc98\ub7fc \ud55c\uc815\uc9d3\ub294\ub2e4\uba74\n\uc774\ub7ec\ud55c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\ub3c4 \ucda9\ubd84\ud569\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \uc774\ub7f0 \ubaa8\ub378\uc740 \uc880 \ub354 \uc77c\ubc18\uc801\uc778\n\uc0c1\ud669\uc5d0 \ud65c\uc6a9\ud560 \uc218 \uc788\uc744\ub9cc\ud07c \uac15\ub825\ud558\uc9c4 \uc54a\uc2b5\ub2c8\ub2e4. \uae30\uacc4\ub97c \ud559\uc2b5\uc2dc\ucf1c\uc11c \uc0ac\ub78c\uacfc\n\uc5ec\ub7ec \uc8fc\uc81c\uc5d0 \ub300\ud574 \uc758\ubbf8 \uc788\ub294 \ub300\ud654\ub97c \ud558\uac8c\ub054 \ud558\ub294 \uac83\uc740 \uc544\uc9c1 \ud574\uacb0\ub418\uc9c0 \uc54a\uc740\n\uc5f0\uad6c \uc8fc\uc81c\uc785\ub2c8\ub2e4. \uadf8\ub7ec\ub098 \ucd5c\uadfc\uc5d0 \ub525\ub7ec\ub2dd\uc774 \uc720\ud589\ud558\uba74\uc11c \uc5ec\ub7ec \uac00\uc9c0\uc758 \uac15\ub825\ud55c\n\uc0dd\uc131 \ubaa8\ub378\uc774 \ub4f1\uc7a5\ud588\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ud55c \ubaa8\ub378\uc758 \ud55c \uc608\uc778 \uad6c\uae00\uc758 `\uc2e0\uacbd \ub300\ud654\n\ubaa8\ub378(Neural Conversational Model) <https://arxiv.org/abs/1506.05869>`__ \uc740\n\ub2e4\uc911 \ub3c4\uba54\uc778 \ub300\ud654 \uc0dd\uc131 \ubaa8\ub378(multi-domain generative conversational models)\n\ubd84\uc57c\uc5d0 \uc788\uc5b4\uc11c \ud070 \uc9c4\uc804\uc744 \uc774\ub8e8\uc5c8\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \ud1b5\ud574 \uc774\ub7ec\ud55c\n\ubaa8\ub378\uc744 PyTorch\ub85c \uad6c\ud604\ud574\ubcf4\ub824 \ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/bot.png\n   :align: center\n   :alt: bot\n\n.. code:: python\n\n  > hello? (\uc548\ub155\ud558\uc138\uc694?)\n  Bot: hello . (\uc548\ub155\ud558\uc138\uc694.)\n  > where am I? (\uc5ec\uae34 \uc5b4\ub514\uc8e0?)\n  Bot: you re in a hospital . (\ubcd1\uc6d0\uc785\ub2c8\ub2e4.)\n  > who are you? (\ub2f9\uc2e0\uc740 \ub204\uad6c\uc2dc\uc8e0?)\n  Bot: i m a lawyer . (\ubcc0\ud638\uc0ac\uc785\ub2c8\ub2e4.)\n  > how are you doing? (\uc5b4\ub5bb\uac8c \uc9c0\ub0b4\uc138\uc694?)\n  Bot: i m fine . (\uc798 \uc9c0\ub0c5\ub2c8\ub2e4.)\n  > are you my friend? (\ub2f9\uc2e0\uc740 \uc81c \uce5c\uad6c\uc778\uac00\uc694?)\n  Bot: no . (\uc544\ub1e8.)\n  > you're under arrest (\ub2f9\uc2e0\uc744 \uccb4\ud3ec\ud558\uaca0\uc2b5\ub2c8\ub2e4)\n  Bot: i m trying to help you ! (\ub09c \ub2f9\uc2e0\uc744 \ub3c4\uc6b0\ub824 \ud558\ub294 \uac81\ub2c8\ub2e4!)\n  > i'm just kidding (\ub18d\ub2f4\uc774\uc5c8\uc5b4\uc694)\n  Bot: i m sorry . (\ubbf8\uc548\ud558\ub124\uc694.)\n  > where are you from? (\uc5b4\ub514\uc11c \uc624\uc168\uc5b4\uc694?)\n  Bot: san francisco . (\uc0cc\ud504\ub780\uc2dc\uc2a4\ucf54\uc694.)\n  > it's time for me to leave (\uc804 \uc774\uc81c \uac00\ubd10\uc57c\uaca0\ub124\uc694)\n  Bot: i know . (\uc54c\uaca0\uc2b5\ub2c8\ub2e4.)\n  > goodbye (\uc548\ub155\ud788 \uacc4\uc138\uc694)\n  Bot: goodbye . (\uc548\ub155\ud788 \uac00\uc138\uc694.)\n\n**\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \ud575\uc2ec \ub0b4\uc6a9**\n\n-  `\ucf54\ub12c \ub300\ud559\uad50\uc758 \uc601\ud654 \uc18d \ub300\ud654 \ub9d0\ubb49\uce58 \ub370\uc774\ud130\uc14b\n   <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__ \uc744\n   \uc77d\uc5b4\uc624\uace0 \uc804\ucc98\ub9ac\ud569\ub2c8\ub2e4\n-  `Luong\uc758 \uc5b4\ud150\uc158(attention) \uba54\ucee4\ub2c8\uc998 <https://arxiv.org/abs/1508.04025>`__ \uc744\n   \uc774\uc6a9\ud558\uc5ec sequence-to-sequence \ubaa8\ub378\uc744 \uad6c\ud604\ud569\ub2c8\ub2e4\n-  \ubbf8\ub2c8\ubc30\uce58\ub97c \uc774\uc6a9\ud558\uc5ec \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\ub97c \ud568\uaed8 \ud559\uc2b5\ud569\ub2c8\ub2e4\n-  \ud0d0\uc695\uc801 \ud0d0\uc0c9 \uae30\ubc95(greedy-search)\uc744 \uc0ac\uc6a9\ud558\ub294 \ub514\ucf54\ub354 \ubaa8\ub4c8\uc744 \uad6c\ud604\ud569\ub2c8\ub2e4\n-  \ud559\uc2b5\ud55c \ucc57\ubd07\uacfc \ub300\ud654\ub97c \ub098\ub220 \ubd05\ub2c8\ub2e4\n\n**\uac10\uc0ac\uc758 \uae00**\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 \ub2e4\uc74c \uc790\ub8cc\uc758 \ub3c4\uc6c0\uc744 \ubc1b\uc544 \uc791\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n1) Yuan-Kuei Wu\uc758 pytorch-chatbot \uad6c\ud604\uccb4:\n   https://github.com/ywk991112/pytorch-chatbot\n\n2) Sean Robertson\uc758 practical-pytorch seq2seq-translation \uc608\uc81c:\n   https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation\n\n3) FloydHub\uc758 \ucf54\ub12c \ub300\ud559\uad50\uc758 \uc601\ud654 \ub9d0\ubb49\uce58 \ub370\uc774\ud130 \uc804\ucc98\ub9ac \ucf54\ub4dc:\n   https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc900\ube44 \ub2e8\uacc4\n---------\n\n\uc2dc\uc791\uc5d0 \uc55e\uc11c, `\uc5ec\uae30 <https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__ \uc5d0\uc11c\nZIP \ud30c\uc77c \ud615\ud0dc\uc758 \ub370\uc774\ud130\ub97c \ub0b4\ub824\ubc1b\uace0, \ud604\uc7ac \ub514\ub809\ud1a0\ub9ac \uc544\ub798\uc5d0 ``data/`` \ub77c\ub294\n\ub514\ub809\ud1a0\ub9ac\ub97c \ub9cc\ub4e4\uc5b4\uc11c \ub0b4\ub824\ubc1b\uc740 \ub370\uc774\ud130\ub97c \uc62e\uaca8\ub450\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n\uadf8 \ub2e4\uc74c\uc5d0\ub294, \uba87 \uac00\uc9c0 \ud544\uc694\ud55c \ub3c4\uad6c\ub4e4\uc744 import \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport torch\nfrom torch.jit import script, trace\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport csv\nimport random\nimport re\nimport os\nimport unicodedata\nimport codecs\nfrom io import open\nimport itertools\nimport math\n\n\nUSE_CUDA = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \uc77d\uae30 & \uc804\ucc98\ub9ac\ud558\uae30\n------------------------\n\n\ub2e4\uc74c \ub2e8\uacc4\ub294 \ub370\uc774\ud130 \ud30c\uc77c\uc758 \ud615\uc2dd\uc744 \uc7ac\uc870\uc815\ud55c \ud6c4, \uc6b0\ub9ac\uac00 \uc791\uc5c5\ud558\uae30 \ud3b8\ud55c\n\uad6c\uc870\ub85c \uc77d\uc5b4\ub4e4\uc774\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n`\ucf54\ub12c \ub300\ud559\uad50\uc758 \uc601\ud654 \uc18d \ub300\ud654 \ub9d0\ubb49\uce58 \ub370\uc774\ud130\uc14b\n<https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>`__ \uc740\n\uc601\ud654 \uc18d \ub4f1\uc7a5 \uc778\ubb3c\uc758 \ub300\ud654\uac00 \ud48d\ubd80\ud558\uac8c \ud3ec\ud568\ub41c \ub370\uc774\ud130\uc14b\uc785\ub2c8\ub2e4.\n\n-  \uc601\ud654 \uc18d \ub4f1\uc7a5 \uc778\ubb3c 10,292 \uc30d\uc774 \ub300\ud654\ub97c 220,579\ubc88 \uc8fc\uace0\ubc1b\uc2b5\ub2c8\ub2e4\n-  \uc601\ud654 617\uac1c\uc758 \ub4f1\uc7a5 \uc778\ubb3c 9,035\uba85\uc774 \ub098\uc635\ub2c8\ub2e4\n-  \ucd1d \ubc1c\ud654(utterance) \uc218\ub294 304,713\ubc88\uc785\ub2c8\ub2e4\n\n\uc774 \ub370\uc774\ud130\uc14b\uc740 \uaddc\ubaa8\ub3c4 \ud06c\uace0 \ub0b4\uc6a9\ub3c4 \ub2e4\uc591\ud558\uba70, \uaca9\uc2dd\uccb4\uc640 \ube44\uaca9\uc2dd\uccb4, \uc5ec\ub7ec\n\uc2dc\uac04\ub300, \uc5ec\ub7ec \uac10\uc815 \uc0c1\ud0dc \ub4f1\uc774 \ub450\ub8e8 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\uc758 \ubc14\ub78c\uc740\n\uc774\ub7ec\ud55c \ub2e4\uc591\uc131\uc73c\ub85c \uc778\ud574 \ubaa8\ub378\uc774 \uacac\uace0\ud574\uc9c0\ub294, \uc989 \ubaa8\ub378\uc774 \uc5ec\ub7ec \uc885\ub958\uc758 \uc785\ub825\n\ubc0f \uc9c8\uc758\uc5d0 \uc798 \ub300\uc751\ud560 \uc218 \uc788\uac8c \ub418\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\uc6b0\uc120\uc740 \uc6d0\ubcf8 \ub370\uc774\ud130 \ud30c\uc77c\uc744 \uba87 \uc904 \uc0b4\ud3b4\ubcf4\uba74\uc11c \ud615\uc2dd\uc774 \uc5b4\ub5bb\uac8c \ub418\uc5b4\uc788\ub294\uc9c0\n\uc0b4\ud3b4 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corpus_name = \"cornell movie-dialogs corpus\"\ncorpus = os.path.join(\"data\", corpus_name)\n\ndef printLines(file, n=10):\n    with open(file, 'rb') as datafile:\n        lines = datafile.readlines()\n    for line in lines[:n]:\n        print(line)\n\nprintLines(os.path.join(corpus, \"movie_lines.txt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc6d0\ud558\ub294 \ud615\uc2dd\uc758 \ub370\uc774\ud130 \ud30c\uc77c\ub85c \ub9cc\ub4e4\uae30\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n\ud3b8\uc758\ub97c \uc704\ud574 \ub370\uc774\ud130\uc758 \ud615\uc2dd\uc744 \uc6d0\ud558\ub294 \ud615\ud0dc\ub85c \ub9cc\ub4e4\ub824\uace0 \ud569\ub2c8\ub2e4. \uac01 \uc904\uc5d0\n*\uc9c8\uc758 \ubb38\uc7a5* \uacfc *\uc751\ub2f5 \ubb38\uc7a5* \uc758 \uc30d\uc774 \ud0ed\uc73c\ub85c \uad6c\ubd84\ub418\uc5b4 \uc788\uac8c\ub054 \ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\ub2e4\uc74c\uc758 \ud568\uc218\ub97c \ud1b5\ud574 *movie_lines.txt* \uc6d0\ubcf8 \ub370\uc774\ud130 \ud30c\uc77c\uc744 \ud30c\uc2f1\ud558\ub824\n\ud569\ub2c8\ub2e4.\n\n-  ``loadLines`` \ub294 \ud30c\uc77c\uc5d0 \ud3ec\ud568\ub41c \ub300\uc0ac\ub97c \ubcc0\ud658\ud558\uc5ec \ud56d\ubaa9(\ub300\uc0ac ID ``lineID``,\n   \uc778\ubb3c ID ``characterID``, \uc601\ud654 ID ``movieID``, \uc778\ubb3c ``character``, \ub300\uc0ac\n   \ub0b4\uc6a9 ``text``)\uc5d0 \ub300\ud55c \uc0ac\uc804 \ud615\ud0dc\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4\n-  ``loadConversations`` \ub294 ``loadLines`` \ub97c \ud1b5\ud574 \uc77d\uc5b4\ub4e4\uc778\n   \ub300\uc0ac(``lines``)\uc758 \ud56d\ubaa9(``fields``)\ub97c *movie_conversations.txt* \uc5d0 \ub098\uc640\n   \uc788\ub294 \ub0b4\uc6a9\uc5d0 \ub9de\ucdb0 \ub300\ud654 \ud615\ud0dc\ub85c \ubb36\uc2b5\ub2c8\ub2e4\n-  ``extractSentencePairs`` \ub294 \ub300\ud654(``conversations``)\uc5d0\uc11c \ubb38\uc7a5 \uc30d\uc744\n   \ucd94\ucd9c\ud569\ub2c8\ub2e4\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud30c\uc77c\uc5d0 \ud3ec\ud568\ub41c \ub300\uc0ac\ub97c \ucabc\uac1c\uc11c \ud56d\ubaa9\uc5d0 \ub300\ud55c \uc0ac\uc804(``dict``) \ud615\ud0dc\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4\ndef loadLines(fileName, fields):\n    lines = {}\n    with open(fileName, 'r', encoding='iso-8859-1') as f:\n        for line in f:\n            values = line.split(\" +++$+++ \")\n            # \ud56d\ubaa9\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4\n            lineObj = {}\n            for i, field in enumerate(fields):\n                lineObj[field] = values[i]\n            lines[lineObj['lineID']] = lineObj\n    return lines\n\n\n# \ub300\uc0ac\uc758 \ud56d\ubaa9\uc744 *movie_conversations.txt* \ub97c \ucc38\uace0\ud558\uc5ec \ub300\ud654 \ud615\ud0dc\ub85c \ubb36\uc2b5\ub2c8\ub2e4\ndef loadConversations(fileName, lines, fields):\n    conversations = []\n    with open(fileName, 'r', encoding='iso-8859-1') as f:\n        for line in f:\n            values = line.split(\" +++$+++ \")\n            # \ud56d\ubaa9\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4\n            convObj = {}\n            for i, field in enumerate(fields):\n                convObj[field] = values[i]\n            # \ubb38\uc790\uc5f4\uc744 \ub9ac\uc2a4\ud2b8\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4(convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n            utterance_id_pattern = re.compile('L[0-9]+')\n            lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n            # \ub300\uc0ac\ub97c \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4\n            convObj[\"lines\"] = []\n            for lineId in lineIds:\n                convObj[\"lines\"].append(lines[lineId])\n            conversations.append(convObj)\n    return conversations\n\n\n# conversations\uc5d0\uc11c \ubb38\uc7a5 \uc30d\uc744 \ucd94\ucd9c\ud569\ub2c8\ub2e4\ndef extractSentencePairs(conversations):\n    qa_pairs = []\n    for conversation in conversations:\n        # \ub300\ud654\ub97c \uc774\ub8e8\ub294 \uac01 \ub300\uc0ac\uc5d0 \ub300\ud574 \ubc18\ubcf5\ubb38\uc744 \uc218\ud589\ud569\ub2c8\ub2e4\n        # \ub300\ud654\uc758 \ub9c8\uc9c0\ub9c9 \ub300\uc0ac\ub294 (\uadf8\uc5d0 \ub300\ud55c \uc751\ub2f5\uc774 \uc5c6\uc73c\ubbc0\ub85c) \ubb34\uc2dc\ud569\ub2c8\ub2e4\n        for i in range(len(conversation[\"lines\"]) - 1):\n            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n            # \uc798\ubabb\ub41c \uc0d8\ud50c\uc740 \uc81c\uac70\ud569\ub2c8\ub2e4(\ub9ac\uc2a4\ud2b8\uac00 \ud558\ub098\ub77c\ub3c4 \ube44\uc5b4 \uc788\ub294 \uacbd\uc6b0)\n            if inputLine and targetLine:\n                qa_pairs.append([inputLine, targetLine])\n    return qa_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \uc774 \ud568\uc218\ub4e4\uc744 \ud638\ucd9c\ud558\uc5ec \uc0c8\ub85c\uc6b4 \ud30c\uc77c\uc778 *formatted_movie_lines.txt* \ub97c\n\ub9cc\ub4ed\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uc0c8 \ud30c\uc77c\uc5d0 \ub300\ud55c \uacbd\ub85c\ub97c \uc815\uc758\ud569\ub2c8\ub2e4\ndatafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n\ndelimiter = '\\t'\n# \uad6c\ubd84\uc790\uc5d0 \ub300\ud574 unescape \ud568\uc218\ub97c \ud638\ucd9c\ud569\ub2c8\ub2e4\ndelimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n\n# \ub300\uc0ac \uc0ac\uc804(dict), \ub300\ud654 \ub9ac\uc2a4\ud2b8(list), \uadf8\ub9ac\uace0 \uac01 \ud56d\ubaa9\uc758 \uc774\ub984\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\nlines = {}\nconversations = []\nMOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\nMOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n\n# \ub300\uc0ac(lines)\ub97c \uc77d\uc5b4\ub4e4\uc5ec \ub300\ud654(conversations)\ub85c \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4\nprint(\"\\nProcessing corpus...\")\nlines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\nprint(\"\\nLoading conversations...\")\nconversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n\n# \uacb0\uacfc\ub97c \uc0c8\ub85c\uc6b4 csv \ud30c\uc77c\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4\nprint(\"\\nWriting newly formatted file...\")\nwith open(datafile, 'w', encoding='utf-8') as outputfile:\n    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n    for pair in extractSentencePairs(conversations):\n        writer.writerow(pair)\n\n# \uba87 \uc904\uc744 \uc608\uc81c \uc0bc\uc544 \ucd9c\ub825\ud574 \ubd05\ub2c8\ub2e4\nprint(\"\\nSample lines from file:\")\nprintLines(datafile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130 \uc77d\uace0 \uc815\ub9ac\ud558\uae30\n~~~~~~~~~~~~~~~~~~~~\n\n\ub2e4\uc74c\uc5d0 \ud574\uc57c \ud560 \uc77c\uc740 \uc5b4\ud718\uc9d1\uc744 \ub9cc\ub4e4\uace0, \uc9c8\uc758/\uc751\ub2f5 \ubb38\uc7a5 \uc30d\uc744 \uba54\ubaa8\ub9ac\ub85c\n\uc77d\uc5b4\ub4e4\uc774\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n\uc6b0\ub9ac\uac00 \ub2e4\ub8e8\ub294 \ub300\uc0c1\uc740 \uc77c\ub828\uc758 **\ub2e8\uc5b4** \ub4e4\uc774\uba70, \ub530\ub77c\uc11c \uc774\ub4e4\uc744 \uc774\uc0b0 \uacf5\uac04 \uc0c1\uc758\n\uc218\uce58(discrete numerical space)\ub85c \uc790\uc5f0\uc2a4\ub7fd\uac8c \ub300\uc751\uc2dc\ud0a4\uae30 \uc5b4\ub835\ub2e4\ub294 \uc810\uc5d0\n\uc720\uc758\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc6b0\ub9ac\ub294 \ub370\uc774\ud130\uc14b \uc548\uc5d0 \ub4e4\uc5b4 \uc788\ub294 \ub2e8\uc5b4\ub97c \uc778\ub371\uc2a4\n\uac12\uc73c\ub85c \ubcc0\ud658\ud558\ub294 \ub9e4\ud551\uc744 \ub530\ub85c \ub9cc\ub4e4\uc5b4\uc57c \ud569\ub2c8\ub2e4.\n\n\uc774\ub97c \uc704\ud574 \uc6b0\ub9ac\ub294 ``Voc`` \ub77c\ub294 \ud074\ub798\uc2a4\ub97c \ub9cc\ub4e4\uc5b4 \ub2e8\uc5b4\uc5d0\uc11c \uc778\ub371\uc2a4\ub85c\uc758\n\ub9e4\ud551, \uc778\ub371\uc2a4\uc5d0\uc11c \ub2e8\uc5b4\ub85c\uc758 \uc5ed \ub9e4\ud551, \uac01 \ub2e8\uc5b4\uc758 \ub4f1\uc7a5 \ud69f\uc218, \uc804\uccb4 \ub2e8\uc5b4 \uc218\n\ub4f1\uc744 \uad00\ub9ac\ud558\ub824 \ud569\ub2c8\ub2e4. \uc774 \ud074\ub798\uc2a4\ub294 \uc5b4\ud718\uc9d1\uc5d0 \uc0c8\ub85c\uc6b4 \ub2e8\uc5b4\ub97c \ucd94\uac00\ud558\ub294\n\uba54\uc11c\ub4dc(``addWord``), \ubb38\uc7a5\uc5d0 \ub4f1\uc7a5\ud558\ub294 \ubaa8\ub4e0 \ub2e8\uc5b4\ub97c \ucd94\uac00\ud558\ub294\n\uba54\uc11c\ub4dc(``addSentence``), \uadf8\ub9ac\uace0 \uc790\uc8fc \ub4f1\uc7a5\ud558\uc9c0 \uc54a\ub294 \ub2e8\uc5b4\ub97c \uc815\ub9ac\ud558\ub294\n\uba54\uc11c\ub4dc(``trim``)\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4. \ub2e8\uc5b4\ub97c \uc815\ub9ac\ud558\ub294 \ub0b4\uc6a9\uc5d0 \ub300\ud574\uc11c\ub294 \ub4a4\uc5d0\uc11c\n\uc880 \ub354 \uc790\uc138\ud788 \uc0b4\ud3b4\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \uae30\ubcf8 \ub2e8\uc5b4 \ud1a0\ud070 \uac12\nPAD_token = 0  # \uc9e7\uc740 \ubb38\uc7a5\uc744 \ucc44\uc6b8(\ud328\ub529, PADding) \ub54c \uc0ac\uc6a9\ud560 \uc81c\ub85c \ud1a0\ud070\nSOS_token = 1  # \ubb38\uc7a5\uc758 \uc2dc\uc791(SOS, Start Of Sentence)\uc744 \ub098\ud0c0\ub0b4\ub294 \ud1a0\ud070\nEOS_token = 2  # \ubb38\uc7a5\uc758 \ub05d(EOS, End Of Sentence)\uc744 \ub098\ud0dc\ub294 \ud1a0\ud070\n\nclass Voc:\n    def __init__(self, name):\n        self.name = name\n        self.trimmed = False\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n        self.num_words = 3  # SOS, EOS, PAD\ub97c \uc13c \uac83\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.num_words\n            self.word2count[word] = 1\n            self.index2word[self.num_words] = word\n            self.num_words += 1\n        else:\n            self.word2count[word] += 1\n\n    # \ub4f1\uc7a5 \ud69f\uc218\uac00 \uae30\uc900 \uc774\ud558\uc778 \ub2e8\uc5b4\ub97c \uc815\ub9ac\ud569\ub2c8\ub2e4\n    def trim(self, min_count):\n        if self.trimmed:\n            return\n        self.trimmed = True\n\n        keep_words = []\n\n        for k, v in self.word2count.items():\n            if v >= min_count:\n                keep_words.append(k)\n\n        print('keep_words {} / {} = {:.4f}'.format(\n            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n        ))\n\n        # \uc0ac\uc804\uc744 \ub2e4\uc2dc \ucd08\uae30\ud654\ud799\ub2c8\ub2e4\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n        self.num_words = 3 # \uae30\ubcf8 \ud1a0\ud070\uc744 \uc13c \uac83\n\n        for word in keep_words:\n            self.addWord(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c \uc5b4\ud718\uc9d1\uacfc \uc9c8\uc758/\uc751\ub2f5 \ubb38\uc7a5 \uc30d\uc744 \uc7ac\uad6c\uc131\ud558\ub824 \ud569\ub2c8\ub2e4. \uadf8\ub7ec\ud55c \ub370\uc774\ud130\ub97c\n\uc0ac\uc6a9\ud558\ub824\uba74 \uadf8 \uc804\uc5d0 \uc57d\uac04\uc758 \uc804\ucc98\ub9ac \uc791\uc5c5\uc744 \uc218\ud589\ud574\uc57c \ud569\ub2c8\ub2e4.\n\n\uc6b0\uc120, ``unicodeToAscii`` \ub97c \uc774\uc6a9\ud558\uc5ec \uc720\ub2c8\ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 \uc544\uc2a4\ud0a4\ub85c \ubcc0\ud658\ud574\uc57c\n\ud569\ub2c8\ub2e4. \ub2e4\uc74c\uc5d0\ub294 \ubaa8\ub4e0 \uae00\uc790\ub97c \uc18c\ubb38\uc790\ub85c \ubcc0\ud658\ud558\uace0, \uc54c\ud30c\ubcb3\ub3c4 \uc544\ub2c8\uace0 \uae30\ubcf8\uc801\uc778\n\ubb38\uc7a5 \ubd80\ud638\ub3c4 \uc544\ub2cc \uae00\uc790\ub294 \uc81c\uac70\ud569\ub2c8\ub2e4(\uc815\uaddc\ud654, ``normalizeString``).\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c\ub294 \ud559\uc2b5\ud560 \ub54c\uc758 \ud3b8\uc758\uc131\uc744 \uc704\ud574\uc11c, \uae38\uc774\uac00 \uc77c\uc815 \uae30\uc900\uc744 \ucd08\uacfc\ud558\ub294,\n\uc989 ``MAX_LENGTH`` \ubcf4\ub2e4 \uae34 \ubb38\uc7a5\uc744 \uc81c\uac70\ud569\ub2c8\ub2e4(``filterPairs``).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10  # \uace0\ub824\ud560 \ubb38\uc7a5\uc758 \ucd5c\ub300 \uae38\uc774\n\n# \uc720\ub2c8\ucf54\ub4dc \ubb38\uc790\uc5f4\uc744 \uc544\uc2a4\ud0a4\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4\n# https://stackoverflow.com/a/518232/2809427 \ucc38\uace0\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# \uc18c\ubb38\uc790\ub85c \ub9cc\ub4e4\uace0, \uacf5\ubc31\uc744 \ub123\uace0, \uc54c\ud30c\ubcb3 \uc678\uc758 \uae00\uc790\ub97c \uc81c\uac70\ud569\ub2c8\ub2e4\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n    s = re.sub(r\"\\s+\", r\" \", s).strip()\n    return s\n\n# \uc9c8\uc758/\uc751\ub2f5 \uc30d\uc744 \uc77d\uc5b4\uc11c voc \uac1d\uccb4\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\ndef readVocs(datafile, corpus_name):\n    print(\"Reading lines...\")\n    # \ud30c\uc77c\uc744 \uc77d\uace0, \ucabc\uac1c\uc5b4 lines\uc5d0 \uc800\uc7a5\ud569\ub2c8\ub2e4\n    lines = open(datafile, encoding='utf-8').\\\n        read().strip().split('\\n')\n    # \uac01 \uc904\uc744 \ucabc\uac1c\uc5b4 pairs\uc5d0 \uc800\uc7a5\ud558\uace0 \uc815\uaddc\ud654\ud569\ub2c8\ub2e4\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n    voc = Voc(corpus_name)\n    return voc, pairs\n\n# \ubb38\uc7a5\uc758 \uc30d 'p'\uc5d0 \ud3ec\ud568\ub41c \ub450 \ubb38\uc7a5\uc774 \ubaa8\ub450 MAX_LENGTH\ub77c\ub294 \uae30\uc900\ubcf4\ub2e4 \uc9e7\uc740\uc9c0\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\ndef filterPair(p):\n    # EOS \ud1a0\ud070\uc744 \uc704\ud574 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ub9c8\uc9c0\ub9c9 \ub2e8\uc5b4\ub97c \ubcf4\uc874\ud574\uc57c \ud569\ub2c8\ub2e4\n    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n\n# \uc870\uac74\uc2dd filterPair\uc5d0 \ub530\ub77c pairs\ub97c \ud544\ud130\ub9c1\ud569\ub2c8\ub2e4\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n# \uc55e\uc5d0\uc11c \uc815\uc758\ud55c \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \ub9cc\ub4e0 voc \uac1d\uccb4\uc640 \ub9ac\uc2a4\ud2b8 pairs\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\ndef loadPrepareData(corpus, corpus_name, datafile, save_dir):\n    print(\"Start preparing training data ...\")\n    voc, pairs = readVocs(datafile, corpus_name)\n    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n    print(\"Counting words...\")\n    for pair in pairs:\n        voc.addSentence(pair[0])\n        voc.addSentence(pair[1])\n    print(\"Counted words:\", voc.num_words)\n    return voc, pairs\n\n\n# voc\uc640 pairs\ub97c \uc77d\uace0 \uc7ac\uad6c\uc131\ud569\ub2c8\ub2e4\nsave_dir = os.path.join(\"data\", \"save\")\nvoc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n# \uac80\uc99d\uc744 \uc704\ud574 pairs\uc758 \uc77c\ubd80 \ub0b4\uc6a9\uc744 \ucd9c\ub825\ud574 \ubd05\ub2c8\ub2e4\nprint(\"\\npairs:\")\nfor pair in pairs[:10]:\n    print(pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ub2e8\uacc4\uac00 \ube68\ub9ac \uc218\ub834\ud558\ub3c4\ub85d \ud558\ub294 \ub610 \ub2e4\ub978 \uc804\ub7b5\uc740 \uc790\uc8fc \uc4f0\uc774\uc9c0 \uc54a\ub294 \ub2e8\uc5b4\ub97c\n\uc5b4\ud718\uc9d1\uc5d0\uc11c \uc81c\uac70\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. \ud53c\ucc98 \uacf5\uac04\uc758 \ud06c\uae30\ub97c \uc904\uc774\uba74 \ubaa8\ub378\uc774\n\ud559\uc2b5\uc744 \ud1b5\ud574 \uadfc\uc0ac\ud558\ub824\ub294 \ud568\uc218\uc758 \ub09c\uc774\ub3c4\ub97c \ub0ae\ucd94\ub294 \ud6a8\uacfc\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294\n\uc774\ub97c \ub450 \ub2e8\uacc4\ub85c \ub098\ub220 \uc9c4\ud589\ud558\ub824 \ud569\ub2c8\ub2e4.\n\n1) ``voc.trim`` \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec ``MIN_COUNT`` \ub77c\ub294 \uae30\uc900 \uc774\ud558\uc758 \ub2e8\uc5b4\ub97c\n   \uc81c\uac70\ud569\ub2c8\ub2e4.\n\n2) \uc81c\uac70\ud558\uae30\ub85c \ud55c \ub2e8\uc5b4\ub97c \ud3ec\ud568\ud558\ub294 \uacbd\uc6b0\ub97c pairs\uc5d0\uc11c \uc81c\uc678\ud569\ub2c8\ub2e4\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "MIN_COUNT = 3    # \uc81c\uc678\ud560 \ub2e8\uc5b4\uc758 \uae30\uc900\uc774 \ub418\ub294 \ub4f1\uc7a5 \ud69f\uc218\n\ndef trimRareWords(voc, pairs, MIN_COUNT):\n    # MIN_COUNT \ubbf8\ub9cc\uc73c\ub85c \uc0ac\uc6a9\ub41c \ub2e8\uc5b4\ub294 voc\uc5d0\uc11c \uc81c\uc678\ud569\ub2c8\ub2e4\n    voc.trim(MIN_COUNT)\n    # \uc81c\uc678\ud560 \ub2e8\uc5b4\uac00 \ud3ec\ud568\ub41c \uacbd\uc6b0\ub97c pairs\uc5d0\uc11c\ub3c4 \uc81c\uc678\ud569\ub2c8\ub2e4\n    keep_pairs = []\n    for pair in pairs:\n        input_sentence = pair[0]\n        output_sentence = pair[1]\n        keep_input = True\n        keep_output = True\n        # \uc785\ub825 \ubb38\uc7a5\uc744 \uac80\uc0ac\ud569\ub2c8\ub2e4\n        for word in input_sentence.split(' '):\n            if word not in voc.word2index:\n                keep_input = False\n                break\n        # \ucd9c\ub825 \ubb38\uc7a5\uc744 \uac80\uc0ac\ud569\ub2c8\ub2e4\n        for word in output_sentence.split(' '):\n            if word not in voc.word2index:\n                keep_output = False\n                break\n\n        # \uc785\ucd9c\ub825 \ubb38\uc7a5\uc5d0 \uc81c\uc678\ud558\uae30\ub85c \ud55c \ub2e8\uc5b4\ub97c \ud3ec\ud568\ud558\uc9c0 \uc54a\ub294 \uacbd\uc6b0\ub9cc\uc744 \ub0a8\uaca8\ub461\ub2c8\ub2e4\n        if keep_input and keep_output:\n            keep_pairs.append(pair)\n\n    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n    return keep_pairs\n\n\n# voc\uc640 pairs\ub97c \uc815\ub3c8\ud569\ub2c8\ub2e4\npairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc744 \uc704\ud55c \ub370\uc774\ud130 \uc900\ube44\ud558\uae30\n---------------------------\n\n\uc0c1\ub2f9\ud55c \ub178\ub825\uc744 \uae30\uc6b8\uc5ec \ub370\uc774\ud130\ub97c \uc804\ucc98\ub9ac\ud558\uace0, \uc798 \uc815\ub9ac\ud558\uc5ec \uc5b4\ud718\uc9d1 \uac1d\uccb4\uc640\n\ubb38\uc7a5 \uc30d\uc758 \ub9ac\uc2a4\ud2b8 \ud615\ud0dc\ub85c \ub9cc\ub4e4\uc5b4\ub450\uae34 \ud588\uc9c0\ub9cc, \uacb0\uad6d \uc6b0\ub9ac\uac00 \ub9cc\ub4e4 \ubaa8\ub378\uc5d0\uc11c\n\uc0ac\uc6a9\ud558\ub294 \uc785\ub825\uc740 \uc218\uce58 \uac12\uc73c\ub85c \uc774\ub8e8\uc5b4\uc9c4 torch \ud150\uc11c\uc785\ub2c8\ub2e4. \ucc98\ub9ac\ud55c \ub370\uc774\ud130\ub97c\n\ubaa8\ub378\uc5d0 \ub9de\ub294 \ud615\ud0dc\ub85c \uc900\ube44\ud558\ub294 \ubc29\ubc95\uc758 \ud558\ub098\uac00 `seq2seq \ubcc0\ud658 \ud29c\ud1a0\ub9ac\uc5bc\n<https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>`__\n\uc5d0 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 \ubc30\uce58 \ud06c\uae30\ub85c 1\uc744 \uc0ac\uc6a9\ud558\uba70, \uc774\ub294 \uc989\n\ubb38\uc7a5\uc5d0 \ub4f1\uc7a5\ud558\ub294 \ub2e8\uc5b4\ub97c \uc5b4\ud718\uc9d1\uc5d0\uc11c\uc758 \uc778\ub371\uc2a4\ub85c \ubcc0\ud658\ud558\uc5ec \ubaa8\ub378\uc5d0 \uc81c\uacf5\ud558\uae30\ub9cc\n\ud558\uba74 \ub41c\ub2e4\ub294 \uc758\ubbf8\uc785\ub2c8\ub2e4.\n\n\uadf8\ub798\ub3c4 \uc5ec\ub7ec\ubd84\uc774 \ud559\uc2b5 \uc18d\ub3c4\ub098 GPU \ubcd1\ub82c \ucc98\ub9ac \uc6a9\ub7c9\uc744 \ud5a5\uc0c1\ud558\uace0 \uc2f6\ub2e4\uba74\n\ubbf8\ub2c8\ubc30\uce58\ub97c \uc774\uc6a9\ud558\uc5ec \ud559\uc2b5\ud574\uc57c \ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\ubbf8\ub2c8\ubc30\uce58\ub97c \uc0ac\uc6a9\ud55c\ub2e4\ub294 \uac83\uc740 \ubc30\uce58\uc5d0 \ud3ec\ud568\ub41c \ubb38\uc7a5 \uae38\uc774\uac00 \ub2ec\ub77c\uc9c8 \uc218 \uc788\ub2e4\ub294\n\uc810\uc5d0 \uc720\uc758\ud574\uc57c \ud55c\ub2e4\ub294 \uac83\uc744 \ub73b\ud569\ub2c8\ub2e4. \uac19\uc740 \ubc30\uce58 \uc548\uc5d0\uc11c \ud06c\uae30\uac00 \ub2e4\ub978\n\ubb38\uc7a5\uc744 \ucc98\ub9ac\ud558\uae30 \uc704\ud574\uc11c\ub294 \ubc30\uce58\uc6a9 \uc785\ub825 \ud150\uc11c\uc758 \ubaa8\uc591\uc744 *(max_length,\nbatch_size)* \ub85c \ub9de\ucdb0\uc57c \ud569\ub2c8\ub2e4. \uc774\ub54c *max_length* \ubcf4\ub2e4 \uc9e7\uc740 \ubb38\uc7a5\uc5d0\n\ub300\ud574\uc11c\ub294 *EOS \ud1a0\ud070* \ub4a4\uc5d0 \uc81c\ub85c \ud1a0\ud070\uc744 \ub367\ubd99\uc774\uba74 \ub429\ub2c8\ub2e4.\n\n\uc601\uc5b4\ub85c \ub41c \ubb38\uc7a5\uc744 \ud150\uc11c\ub85c \ubcc0\ud658\ud558\uae30 \uc704\ud574 \ub2e8\uc21c\ud788 \uadf8\uc5d0 \ub300\uc751\ud558\ub294 \uc778\ub371\uc2a4\ub97c\n\uc0ac\uc6a9\ud558\uace0(``indexesFromSentence``) \uc81c\ub85c \ud1a0\ud070\uc744 \ud328\ub529\ud55c\ub2e4\uace0 \ud574\ubd05\uc2dc\ub2e4.\n\uadf8\ub7ec\uba74 \ud150\uc11c\uc758 \ubaa8\uc591\uc774 *(batch_size, max_length)* \uc774 \ub418\uace0, \uccab \ubc88\uc9f8 \ucc28\uc6d0\uc5d0\n\ub300\ud574 \uc778\ub371\uc2f1\uc744 \uc218\ud589\ud558\uba74 \ubaa8\ub4e0 \uc2dc\uac04\ub300\ubcc4 \ubb38\uc7a5\uc774 \uc804\ubd80 \ubc18\ud658\ub420 \uac83\uc785\ub2c8\ub2e4.\n\uadf8\ub7ec\ub098 \uc6b0\ub9ac\ub294 \ubc30\uce58\ub97c \uc2dc\uac04\uc5d0 \ub530\ub77c, \uadf8\ub9ac\uace0 \ubc30\uce58\uc5d0 \ud3ec\ud568\ub41c \ubaa8\ub4e0 \ubb38\uc7a5\uc5d0\n\ub300\ud574 \uc778\ub371\uc2f1\ud560 \uc218\ub3c4 \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc6b0\ub9ac\ub294 \uc785\ub825 \ubc30\uce58\uc758 \ubaa8\uc591\uc744\n\ub4a4\uc9d1\uc5b4\uc11c *(max_length, batch_size)* \ud615\ud0dc\ub85c \ub9cc\ub4e4 \uac83\uc785\ub2c8\ub2e4. \uadf8\ub7ec\uace0 \ub09c\n\ud6c4\uc5d0 \uccab \ubc88\uc9f8 \ucc28\uc6d0\uc5d0 \ub300\ud574 \uc778\ub371\uc2f1\ud558\uba74 \ubc30\uce58\uc5d0 \ud3ec\ud568\ub41c \ubaa8\ub4e0 \ubb38\uc7a5\uc744 \uc2dc\uac04\uc5d0\n\ub300\ud574 \uc778\ub371\uc2f1\ud55c \uacb0\uacfc\ub97c \ubc18\ud658\ud558\uac8c \ub429\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uc774 \ub4a4\uc9d1\uae30 \uc791\uc5c5\uc744\n``zeroPadding`` \ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \ubb35\uc2dc\uc801\uc73c\ub85c \uc218\ud589\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/seq2seq_batches.png\n   :align: center\n   :alt: batches\n\n``inputVar`` \ud568\uc218\ub294 \ubb38\uc7a5\uc744 \ud150\uc11c\ub85c \ubcc0\ud658\ud558\ub294, \uadf8\ub9ac\uace0 \uad81\uadf9\uc801\uc73c\ub85c\ub294 \uc81c\ub85c\n\ud328\ub529\ud558\uc5ec \uc62c\ubc14\ub978 \ubaa8\uc591\uc73c\ub85c \ub9de\ucd98 \ud150\uc11c\ub97c \ub9cc\ub4dc\ub294 \uc791\uc5c5\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uc774\n\ud568\uc218\ub294 \uac01 \ubc30\uce58\uc5d0 \ud3ec\ud568\ub41c \uc2dc\ud000\uc2a4\uc758 \uae38\uc774(``lengths``)\ub85c \uad6c\uc131\ub41c \ud150\uc11c\ub3c4 \uac19\uc774\n\ubc18\ud658\ud569\ub2c8\ub2e4. \uadf8\ub9ac\uace0 \uc6b0\ub9ac\ub294 \uc774\ub97c \ub098\uc911\uc5d0 \ub514\ucf54\ub354\ub85c \ub118\uaca8\uc904 \uac83\uc785\ub2c8\ub2e4.\n\n``outputVar`` \ud568\uc218\ub294 ``inputVar`` \uc640 \ube44\uc2b7\ud55c \uc791\uc5c5\uc744 \uc218\ud589\ud558\uc9c0\ub9cc, ``lengths``\n\ud150\uc11c\ub97c \ubc18\ud658\ud558\ub294 \ub300\uc2e0\uc5d0 \uc774\uc9c4 \ub9c8\uc2a4\ud06c\ub85c \uad6c\uc131\ub41c \ud150\uc11c\uc640 \ubaa9\ud45c \ubb38\uc7a5\uc758 \ucd5c\ub300\n\uae38\uc774\ub97c \uac19\uc774 \ubc18\ud658\ud569\ub2c8\ub2e4. \uc774\uc9c4 \ub9c8\uc2a4\ud06c \ud150\uc11c\ub294 \ucd9c\ub825\uc5d0 \ud574\ub2f9\ud558\ub294 \ubaa9\ud45c \ud150\uc11c\uc640\n\uadf8 \ubaa8\uc591\uc774 \uac19\uc9c0\ub9cc, \ud328\ub529 \ud1a0\ud070(*PAD_token*)\uc5d0 \ud574\ub2f9\ud558\ub294 \uacbd\uc6b0\uc5d0\ub294 \uac12\uc774 0\uc774\uba70\n\ub098\uba38\uc9c0 \uacbd\uc6b0\uc758 \uac12\uc740 1\uc785\ub2c8\ub2e4.\n\n``batch2TrainData`` \ub294 \ub2e8\uc21c\ud788 \uc5ec\ub7ec \uc30d\uc744 \uc785\ub825\uc73c\ub85c \ubc1b\uc544\uc11c, \uc55e\uc11c \uc124\uba85\ud55c\n\ud568\uc218\ub97c \uc774\uc6a9\ud558\uc5ec \uc785\ub825 \ubc0f \ubaa9\ud45c \ud150\uc11c\ub97c \uad6c\ud558\uc5ec \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(voc, sentence):\n    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n\n\ndef zeroPadding(l, fillvalue=PAD_token):\n    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n\ndef binaryMatrix(l, value=PAD_token):\n    m = []\n    for i, seq in enumerate(l):\n        m.append([])\n        for token in seq:\n            if token == PAD_token:\n                m[i].append(0)\n            else:\n                m[i].append(1)\n    return m\n\n# \uc785\ub825 \uc2dc\ud000\uc2a4 \ud150\uc11c\uc5d0 \ud328\ub529\ud55c \uacb0\uacfc\uc640 lengths\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\ndef inputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    padVar = torch.LongTensor(padList)\n    return padVar, lengths\n\n# \ud328\ub529\ud55c \ubaa9\ud45c \uc2dc\ud000\uc2a4 \ud150\uc11c, \ud328\ub529 \ub9c8\uc2a4\ud06c, \uadf8\ub9ac\uace0 \ucd5c\ub300 \ubaa9\ud45c \uae38\uc774\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\ndef outputVar(l, voc):\n    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n    max_target_len = max([len(indexes) for indexes in indexes_batch])\n    padList = zeroPadding(indexes_batch)\n    mask = binaryMatrix(padList)\n    mask = torch.ByteTensor(mask)\n    padVar = torch.LongTensor(padList)\n    return padVar, mask, max_target_len\n\n# \uc785\ub825 \ubc30\uce58\ub97c \uc774\ub8e8\ub294 \uc30d\uc5d0 \ub300\ud55c \ubaa8\ub4e0 \uc544\uc774\ud15c\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4\ndef batch2TrainData(voc, pair_batch):\n    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n    input_batch, output_batch = [], []\n    for pair in pair_batch:\n        input_batch.append(pair[0])\n        output_batch.append(pair[1])\n    inp, lengths = inputVar(input_batch, voc)\n    output, mask, max_target_len = outputVar(output_batch, voc)\n    return inp, lengths, output, mask, max_target_len\n\n\n# \uac80\uc99d\uc6a9 \uc608\uc2dc\nsmall_batch_size = 5\nbatches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\ninput_variable, lengths, target_variable, mask, max_target_len = batches\n\nprint(\"input_variable:\", input_variable)\nprint(\"lengths:\", lengths)\nprint(\"target_variable:\", target_variable)\nprint(\"mask:\", mask)\nprint(\"max_target_len:\", max_target_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc815\uc758\ud558\uae30\n-------------\n\nSeq2Seq \ubaa8\ub378\n~~~~~~~~~~~~\n\n\uc6b0\ub9ac \ucc57\ubd07\uc758 \ub450\ub1cc\uc5d0 \ud574\ub2f9\ud558\ub294 \ubaa8\ub378\uc740 sequence-to-sequence (seq2seq)\n\ubaa8\ub378\uc785\ub2c8\ub2e4. seq2seq \ubaa8\ub378\uc758 \ubaa9\ud45c\ub294 \uac00\ubcc0 \uae38\uc774 \uc2dc\ud000\uc2a4\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uace0,\n\ud06c\uae30\uac00 \uace0\uc815\ub41c \ubaa8\ub378\uc744 \uc774\uc6a9\ud558\uc5ec, \uac00\ubcc0 \uae38\uc774 \uc2dc\ud000\uc2a4\ub97c \ucd9c\ub825\uc73c\ub85c \ubc18\ud658\ud558\ub294\n\uac83\uc785\ub2c8\ub2e4.\n\n`Sutskever \ub4f1 <https://arxiv.org/abs/1409.3215>`__ \uc740 \ub450 \uac1c\uc758 \ub3c5\ub9bd\ub41c\n\uc21c\ud658 \uc2e0\uacbd\ub9dd\uc744 \uac19\uc774 \uc774\uc6a9\ud558\uc5ec \uc774\ub7ec\ud55c \ubaa9\uc801\uc744 \ub2ec\uc131\ud560 \uc218 \uc788\uc74c\uc744 \ubc1c\uacac\ud588\uc2b5\ub2c8\ub2e4.\nRNN \ud558\ub098\ub294 **\uc778\ucf54\ub354** \ub85c, \uac00\ubcc0 \uae38\uc774 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uace0\uc815\ub41c \uae38\uc774\uc758 \ubb38\ub9e5\n\ubca1\ud130(context vector)\ub85c \uc778\ucf54\ub529\ud569\ub2c8\ub2e4. \uc774\ub860\uc0c1 \ubb38\ub9e5 \ubca1\ud130(RNN\uc758 \ub9c8\uc9c0\ub9c9\n\uc740\ub2c9 \ub808\uc774\uc5b4)\ub294 \ubd07\uc5d0\uac8c \uc785\ub825\uc73c\ub85c \uc8fc\uc5b4\uc9c0\ub294 \uc9c8\uc758 \ubb38\uc7a5\uc5d0 \ub300\ud55c \uc758\ubbf8\ub860\uc801 \uc815\ubcf4\ub97c\n\ub2f4\uace0 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4. \ub450 \ubc88\uc9f8 RNN\uc740 **\ub514\ucf54\ub354** \uc785\ub2c8\ub2e4. \ub514\ucf54\ub354\ub294 \ub2e8\uc5b4 \ud558\ub098\uc640\n\ubb38\ub9e5 \ubca1\ud130\ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uace0, \uc2dc\ud000\uc2a4\uc758 \ub2e4\uc74c \ub2e8\uc5b4\uac00 \ubb34\uc5c7\uc77c\uc9c0\ub97c \ucd94\ub860\ud558\uc5ec\n\ubc18\ud658\ud558\uba70, \ub2e4\uc74c \ub2e8\uacc4\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc740\ub2c9 \uc0c1\ud0dc\ub3c4 \uac19\uc774 \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/seq2seq_ts.png\n   :align: center\n   :alt: model\n\n\uadf8\ub9bc \ucd9c\ucc98:\nhttps://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc778\ucf54\ub354\n~~~~~~\n\n\uc778\ucf54\ub354 RNN\uc740 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ud1a0\ud070 \ub2e8\uc704\ub85c(\uc608\ub97c \ub4e4\uc5b4, \ub2e8\uc5b4 \ub2e8\uc704\ub85c) \ud55c\ubc88\uc5d0\n\ud558\ub098\uc529 \uc0b4\ud3b4\ubcf4\uba70 \uc9c4\ud589\ud569\ub2c8\ub2e4. \uadf8\ub9ac\uace0 \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \"\ucd9c\ub825\" \ubca1\ud130\uc640 \"\uc740\ub2c9\n\uc0c1\ud0dc\" \ubca1\ud130\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4. \uc740\ub2c9 \uc0c1\ud0dc \ubca1\ud130\ub294 \ub2e4\uc74c \ub2e8\uacc4\ub97c \uc9c4\ud589\ud560 \ub54c \uac19\uc774\n\uc0ac\uc6a9\ub418\uba70, \ucd9c\ub825 \ubca1\ud130\ub294 \ucc28\ub840\ub300\ub85c \uae30\ub85d\ub429\ub2c8\ub2e4. \uc778\ucf54\ub354\ub294 \uc2dc\ud000\uc2a4\uc758 \uac01 \uc9c0\uc810\uc5d0\n\ub300\ud574 \ud30c\uc545\ud55c \ubb38\ub9e5\uc744 \uace0\ucc28\uc6d0 \uacf5\uac04\uc5d0 \uc788\ub294 \uc810\ub4e4\uc758 \uc9d1\ud569\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n\ub098\uc911\uc5d0 \ub514\ucf54\ub354\ub294 \uc774\ub97c \uc774\uc6a9\ud558\uc5ec \uc8fc\uc5b4\uc9c4 \ubb38\uc81c\uc5d0 \ub300\ud574 \uc758\ubbf8 \uc788\ub294 \ucd9c\ub825\uc744\n\uad6c\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n\uc778\ucf54\ub354\uc758 \ud575\uc2ec \ubd80\ubd84\uc5d0\ub294 \ub2e4\uc911 \ub808\uc774\uc5b4 \uac8c\uc774\ud2b8 \uc21c\ud658 \uc720\ub2db(multi-layered Gated\nRecurrent Unit)\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub294 `Cho \ub4f1 <https://arxiv.org/pdf/1406.1078v3.pdf>`__\n\uc774 2014\ub144\uc5d0 \uace0\uc548\ud55c \uac83\uc785\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 GRU\ub97c \uc591\ubc29\ud5a5\uc73c\ub85c \ubcc0\ud658\ud55c \ud615\ud0dc\ub97c\n\uc0ac\uc6a9\ud560 \uac83\uc774\uba70, \uc774\ub294 \ubcf8\uc9c8\uc801\uc73c\ub85c \ub450 \uac1c\uc758 \ub3c5\ub9bd\ub41c RNN\uc774 \uc874\uc7ac\ud55c\ub2e4\ub294\n\uc758\ubbf8\uc785\ub2c8\ub2e4. \ud558\ub098\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uc6d0\ub798 \uc2dc\ud000\uc2a4\uc5d0\uc11c\uc758 \uc21c\uc11c\ub85c \ucc98\ub9ac\ud558\uba70,\n\ub2e4\ub978 \ud558\ub098\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \uc5ed\uc21c\uc73c\ub85c \ucc98\ub9ac\ud569\ub2c8\ub2e4. \ub2e8\uacc4\ub9c8\ub2e4 \uac01 \ub124\ud2b8\uc6cc\ud06c\uc758\n\ucd9c\ub825\uc744 \ud569\uc0b0\ud569\ub2c8\ub2e4. \uc591\ubc29\ud5a5 GRU\ub97c \uc0ac\uc6a9\ud558\uba74 \uacfc\uac70\uc640 \ubbf8\ub798\uc758 \ubb38\ub9e5\uc744 \ud568\uaed8\n\uc778\ucf54\ub529\ud560 \uc218 \uc788\ub2e4\ub294 \uc7a5\uc810\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc591\ubc29\ud5a5 RNN:\n\n.. figure:: /_static/img/chatbot/RNN-bidirectional.png\n   :width: 70%\n   :align: center\n   :alt: rnn_bidir\n\n\uadf8\ub9bc \ucd9c\ucc98: https://colah.github.io/posts/2015-09-NN-Types-FP/\n\n``embedding`` \ub808\uc774\uc5b4\uac00 \ub2e8\uc5b4 \uc778\ub371\uc2a4\ub97c \uc784\uc758 \ud06c\uae30\uc758 \ud53c\ucc98 \uacf5\uac04\uc73c\ub85c\n\uc778\ucf54\ub529\ud558\ub294 \ub370 \uc0ac\uc6a9\ub418\uc5c8\uc74c\uc5d0 \uc720\uc758\ud558\uae30 \ubc14\ub78d\ub2c8\ub2e4. \uc6b0\ub9ac\uc758 \ubaa8\ub378\uc5d0\uc11c\ub294 \uc774\n\ub808\uc774\uc5b4\uac00 \uac01 \ub2e8\uc5b4\ub97c \ud06c\uae30\uac00 *hidden_size* \uc778 \ud53c\ucc98 \uacf5\uac04\uc73c\ub85c \ub9e4\ud551\ud560\n\uac83\uc785\ub2c8\ub2e4. \ud559\uc2b5\uc744 \uac70\uce58\uba74 \uc11c\ub85c \ub73b\uc774 \uc720\uc0ac\ud55c \ub2e8\uc5b4\ub294 \uc758\ubbf8\uc801\uc73c\ub85c \uc720\uc0ac\ud558\uac8c\n\uc778\ucf54\ub529\ub420 \uac83\uc785\ub2c8\ub2e4.\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c, RNN \ubaa8\ub4c8\uc5d0 \ud328\ub529\ub41c \ubc30\uce58\ub97c \ubcf4\ub0b4\ub824\uba74 RNN\uacfc \uc5f0\uacb0\ub41c \ubd80\ubd84\uc5d0\uc11c\n\ud328\ud0b9 \ubc0f \uc5b8\ud328\ud0b9\ud558\ub294 \uc791\uc5c5\uc744 \uc218\ud589\ud574\uc57c \ud569\ub2c8\ub2e4. \uac01\uac01\uc740\n``nn.utils.rnn.pack_padded_sequence`` \uc640\n``nn.utils.rnn.pad_packed_sequence`` \ub97c \ud1b5\ud574 \uc218\ud589\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n**\uacc4\uc0b0 \uadf8\ub798\ud504:**\n\n   1) \ub2e8\uc5b4 \uc778\ub371\uc2a4\ub97c \uc784\ubca0\ub529\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n   2) RNN \ubaa8\ub4c8\uc744 \uc704\ud55c \ud328\ub529\ub41c \ubc30\uce58 \uc2dc\ud000\uc2a4\ub97c \ud328\ud0b9\ud569\ub2c8\ub2e4.\n   3) GRU\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4.\n   4) \ud328\ub529\uc744 \uc5b8\ud328\ud0b9\ud569\ub2c8\ub2e4.\n   5) \uc591\ubc29\ud5a5 GRU\uc758 \ucd9c\ub825\uc744 \ud569\uc0b0\ud569\ub2c8\ub2e4.\n   6) \ucd9c\ub825\uacfc \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n**\uc785\ub825:**\n\n-  ``input_seq``: \uc785\ub825 \uc2dc\ud000\uc2a4 \ubc30\uce58. shape=\\ *(max_length,\n   batch_size)*\n-  ``input_lengths``: \ubc30\uce58\uc5d0 \ud3ec\ud568\ub41c \uac01 \ubb38\uc7a5\uc758 \uae38\uc774\ub85c \uad6c\uc131\ub41c \ub9ac\uc2a4\ud2b8.\n   shape=\\ *(batch_size)*\n-  ``hidden``: \uc740\ub2c9 \uc0c1\ud0dc. shape=\\ *(n_layers x num_directions,\n   batch_size, hidden_size)*\n\n**\ucd9c\ub825:**\n\n-  ``outputs``: GRU\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \ub808\uc774\uc5b4\uc5d0 \ub300\ud55c \ucd9c\ub825 \ud53c\ucc98 \uac12(\uc591\ubc29\ud5a5\n   (\ucd9c\ub825\uc744 \ud569\uc0b0\ud55c \uac83). shape=\\ *(max_length, batch_size, hidden_size)*\n-  ``hidden``: GRU\uc758 \ucd5c\uc885 \uc740\ub2c9 \uc0c1\ud0dc. shape=\\ *(n_layers x\n   num_directions, batch_size, hidden_size)*\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n        super(EncoderRNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.embedding = embedding\n\n        # GRU\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4. input_size\uc640 hidden_size \ud328\ub7ec\ubbf8\ud130\ub294 \ub458 \ub2e4 'hidden_size'\ub85c\n        # \ub461\ub2c8\ub2e4. \uc774\ub294 \uc6b0\ub9ac \uc785\ub825\uc758 \ud06c\uae30\uac00 hideen_size \ub9cc\ud07c\uc758 \ud53c\ucc98\ub97c \uac16\ub294 \ub2e8\uc5b4 \uc784\ubca0\ub529\uc774\uae30\n        # \ub54c\ubb38\uc785\ub2c8\ub2e4.\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n\n    def forward(self, input_seq, input_lengths, hidden=None):\n        # \ub2e8\uc5b4 \uc778\ub371\uc2a4\ub97c \uc784\ubca0\ub529\uc73c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4\n        embedded = self.embedding(input_seq)\n        # RNN \ubaa8\ub4c8\uc744 \uc704\ud55c \ud328\ub529\ub41c \ubc30\uce58 \uc2dc\ud000\uc2a4\ub97c \ud328\ud0b9\ud569\ub2c8\ub2e4\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n        # GRU\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4\n        outputs, hidden = self.gru(packed, hidden)\n        # \ud328\ub529\uc744 \uc5b8\ud328\ud0b9\ud569\ub2c8\ub2e4\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n        # \uc591\ubc29\ud5a5 GRU\uc758 \ucd9c\ub825\uc744 \ud569\uc0b0\ud569\ub2c8\ub2e4\n        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n        # \ucd9c\ub825\uacfc \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\n        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub514\ucf54\ub354\n~~~~~~\n\n\ub514\ucf54\ub354 RNN\uc740 \ud1a0\ud070 \ub2e8\uc704\ub85c \uc751\ub2f5 \ubb38\uc7a5\uc744 \uc0dd\uc131\ud558\ub294 \uc5ed\ud560\uc744 \uc218\ud589\ud569\ub2c8\ub2e4. \uc774\ub54c\n\uc778\ucf54\ub354\uc758 \ubb38\ubc31 \ubca1\ud130\ub97c \uc0ac\uc6a9\ud558\uba70, \ub0b4\ubd80 \uc740\ub2c9 \uc0c1\ud0dc\uc5d0 \ub530\ub77c \uc2dc\ud000\uc2a4\uc758 \ub2e4\uc74c\n\ub2e8\uc5b4\ub97c \uc0dd\uc131\ud558\uac8c \ub429\ub2c8\ub2e4. \ub514\ucf54\ub354\ub294 *EOS_token*, \uc989 \ubb38\uc7a5\uc758 \ub05d\uc744 \ub098\ud0c0\ub0b4\ub294\n\ud1a0\ud070\uc744 \ucd9c\ub825\ud560 \ub54c\uae4c\uc9c0 \uacc4\uc18d \ub2e8\uc5b4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc6d0\ub798\uc758 seq2seq \ub514\ucf54\ub354\uc5d0\ub294\n\uc54c\ub824\uc9c4 \ubb38\uc81c\uc810\uc774 \uc788\uc2b5\ub2c8\ub2e4. \ub9cc\uc57d \uc6b0\ub9ac\uac00 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \uc758\ubbf8\ub97c \uc778\ucf54\ub529\ud560\n\ub54c \ubb38\ub9e5 \ubca1\ud130\uc5d0\ub9cc \uc804\uc801\uc73c\ub85c \uc758\uc874\ud55c\ub2e4\uba74, \uadf8 \uacfc\uc815 \uc911\uc5d0 \uc815\ubcf4 \uc190\uc2e4\uc774 \uc77c\uc5b4\ub0a0\n\uac00\ub2a5\uc131\uc774 \ub192\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774\ub294 \ud2b9\ud788 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \uae38\uc774\uac00 \uae38 \ub54c \uadf8\ub7ec\ud558\uba70,\n\uc774 \ub54c\ubb38\uc5d0 \ub514\ucf54\ub354\uc758 \uae30\ub2a5\uc774 \ud06c\uac8c \uc81c\ud55c\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud55c \ubc29\ud3b8\uc73c\ub85c, `Bahdanau \ub4f1\n<https://arxiv.org/abs/1409.0473>`__ \uc740 '\uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998'\uc744\n\uace0\uc548\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub294 \ub514\ucf54\ub354\uac00 \ub9e4 \ub2e8\uacc4\uc5d0 \ub300\ud574 \uace0\uc815\ub41c \ubb38\ub9e5\uc744 \uacc4\uc18d \uc0ac\uc6a9\ud558\ub294\n\uac83\uc774 \uc544\ub2c8\ub77c, \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \ubd80\ubd84\uc5d0 \uc9d1\uc911\ud558\uac8c \ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4.\n\n\ub192\uc740 \ucc28\uc6d0\uc5d0\uc11c \uc774\uc57c\uae30 \ud558\uc790\uba74, \uc5b4\ud150\uc158\uc740 \ub514\ucf54\ub354\uc758 \ud604\uc7ac \uc740\ub2c9 \uc0c1\ud0dc\uc640 \uc778\ucf54\ub354\uc758\n\ucd9c\ub825\uc744 \ubc14\ud0d5\uc73c\ub85c \uacc4\uc0b0\ub429\ub2c8\ub2e4. \ucd9c\ub825\ub418\ub294 \uc5b4\ud150\uc158 \uac00\uc911\uce58\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc640\n\ub3d9\uc77c\ud55c \ubaa8\uc591\uc744 \uac00\uc9d1\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc774\ub97c \uc778\ucf54\ub354\uc758 \ucd9c\ub825\uacfc \uacf1\ud560 \uc218 \uc788\uace0, \uadf8\n\uacb0\uacfc\ub85c \uc5bb\uac8c \ub418\ub294 \uac00\uc911\uce58 \ud569\uc740 \uc778\ucf54\ub354\uc758 \ucd9c\ub825\uc5d0\uc11c \uc5b4\ub290 \ubd80\ubd84\uc5d0 \uc9d1\uc911\ud574\uc57c\n\ud560\uc9c0\ub97c \uc54c\ub824\uc90d\ub2c8\ub2e4. `Sean Robertson <https://github.com/spro>`__\n\uc758 \uadf8\ub9bc\uc5d0 \uc774\ub7ec\ud55c \ub0b4\uc6a9\uc774 \uc798 \uc124\uba85\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/attn2.png\n   :align: center\n   :alt: attn2\n\n`Luong \ub4f1 <https://arxiv.org/abs/1508.04025>`__ \uc740 Bahdanau\uc758 \uae30\ucd08 \uc5f0\uad6c\ub97c\n\ub354\uc6b1 \ubc1c\uc804\uc2dc\ud0a8 '\uc804\uc5ed(global) \uc5b4\ud150\uc158'\uc744 \uc81c\uc548\ud588\uc2b5\ub2c8\ub2e4. '\uc804\uc5ed \uc5b4\ud150\uc158'\uc758\n\ud575\uc2ec\uc801\uc778 \ucc28\uc774\uc810\uc740 \uc778\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ubaa8\ub450 \uace0\ub824\ud55c\ub2e4\ub294 \uc810\uc785\ub2c8\ub2e4. \uc774\ub294\nBahdanau \ub4f1\uc758 '\uc9c0\uc5ed(local) \uc5b4\ud150\uc158' \ubc29\uc2dd\uc774 \ud604\uc7ac \uc2dc\uc810\uc5d0 \ub300\ud55c \uc778\ucf54\ub354\uc758\n\uc740\ub2c9 \uc0c1\ud0dc\ub9cc\uc744 \uace0\ub824\ud55c\ub2e4\ub294 \uc810\uacfc \ub2e4\ub978 \ubd80\ubd84\uc785\ub2c8\ub2e4. '\uc804\uc5ed \uc5b4\ud150\uc158'\uc758 \ub610 \ub2e4\ub978\n\ucc28\uc774\uc810\uc740 \uc5b4\ud150\uc158\uc5d0 \ub300\ud55c \uac00\uc911\uce58, \ud639\uc740 \uc5d0\ub108\uc9c0\ub97c \uacc4\uc0b0\ud560 \ub54c \ud604\uc7ac \uc2dc\uc810\uc5d0 \ub300\ud55c\n\ub514\ucf54\ub354\uc758 \uc740\ub2c9 \uc0c1\ud0dc\ub9cc\uc744 \uc0ac\uc6a9\ud55c\ub2e4\ub294 \uc810\uc785\ub2c8\ub2e4. Bahdanau \ub4f1\uc740 \uc5b4\ud150\uc158\uc744\n\uacc4\uc0b0\ud560 \ub54c \ub514\ucf54\ub354\uc758 \uc774\uc804 \ub2e8\uacc4 \uc0c1\ud0dc\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \ud65c\uc6a9\ud569\ub2c8\ub2e4. \ub610\ud55c Luong \ub4f1\uc758\n\ubc29\ubc95\uc5d0\uc11c\ub294 \uc778\ucf54\ub354\uc758 \ucd9c\ub825\uacfc \ub514\ucf54\ub354\uc758 \ucd9c\ub825\uc5d0 \ub300\ud55c \uc5b4\ud150\uc158 \uc5d0\ub108\uc9c0\ub97c \uacc4\uc0b0\ud558\ub294\n\ubc29\ubc95\uc744 \uc81c\uacf5\ud558\uba70, \uc774\ub97c '\uc810\uc218 \ud568\uc218(score function)'\ub77c \ubd80\ub985\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/scores.png\n   :width: 60%\n   :align: center\n   :alt: scores\n\n\uc774\ub54c $h_t$ \ub294 \ubaa9\ud45c \ub514\ucf54\ub354\uc758 \ud604\uc7ac \uc0c1\ud0dc\ub97c, $\\bar{h}_s$ \ub294 \uc778\ucf54\ub354\uc758\n\ubaa8\ub4e0 \uc0c1\ud0dc\ub97c \ub73b\ud569\ub2c8\ub2e4.\n\n\uc885\ud569\ud574 \ubcf4\uba74, \uc804\uc5ed \uc5b4\ud150\uc158 \uba54\ucee4\ub2c8\uc998\uc744 \ub2e4\uc74c \uadf8\ub9bc\uacfc \uac19\uc774 \uc694\uc57d\ud560 \uc218 \uc788\uc744\n\uac83\uc785\ub2c8\ub2e4. \uc6b0\ub9ac\uac00 '\uc5b4\ud150\uc158 \ub808\uc774\uc5b4'\ub97c ``Attn`` \ub77c\ub294 \ub3c5\ub9bd\uc801\uc778 ``nn.Module`` \ub85c\n\uad6c\ud604\ud560 \uac83\uc784\uc5d0 \uc720\uc758\ud558\uae30 \ubc14\ub78d\ub2c8\ub2e4. \uc774 \ubaa8\ub4c8\uc758 \ucd9c\ub825\uc740 \ubaa8\uc591\uc774 *(batch_size, 1,\nmax_length)* \uc778 \uc815\uaddc\ud654\ub41c softmax \uac00\uc911\uce58 \ud150\uc11c\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/global_attn.png\n   :align: center\n   :width: 60%\n   :alt: global_attn\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Luong \uc5b4\ud150\uc158 \ub808\uc774\uc5b4\nclass Attn(nn.Module):\n    def __init__(self, method, hidden_size):\n        super(Attn, self).__init__()\n        self.method = method\n        if self.method not in ['dot', 'general', 'concat']:\n            raise ValueError(self.method, \"is not an appropriate attention method.\")\n        self.hidden_size = hidden_size\n        if self.method == 'general':\n            self.attn = nn.Linear(self.hidden_size, hidden_size)\n        elif self.method == 'concat':\n            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n\n    def dot_score(self, hidden, encoder_output):\n        return torch.sum(hidden * encoder_output, dim=2)\n\n    def general_score(self, hidden, encoder_output):\n        energy = self.attn(encoder_output)\n        return torch.sum(hidden * energy, dim=2)\n\n    def concat_score(self, hidden, encoder_output):\n        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n        return torch.sum(self.v * energy, dim=2)\n\n    def forward(self, hidden, encoder_outputs):\n        # Attention \uac00\uc911\uce58(\uc5d0\ub108\uc9c0)\ub97c \uc81c\uc548\ub41c \ubc29\ubc95\uc5d0 \ub530\ub77c \uacc4\uc0b0\ud569\ub2c8\ub2e4\n        if self.method == 'general':\n            attn_energies = self.general_score(hidden, encoder_outputs)\n        elif self.method == 'concat':\n            attn_energies = self.concat_score(hidden, encoder_outputs)\n        elif self.method == 'dot':\n            attn_energies = self.dot_score(hidden, encoder_outputs)\n\n        # max_length\uc640 batch_size\uc758 \ucc28\uc6d0\uc744 \ub4a4\uc9d1\uc2b5\ub2c8\ub2e4\n        attn_energies = attn_energies.t()\n\n        # \uc815\uaddc\ud654\ub41c softmax \ud655\ub960 \uc810\uc218\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4 (\ucc28\uc6d0\uc744 \ub298\ub824\uc11c)\n        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\ucc98\ub7fc \uc5b4\ud150\uc158 \uc11c\ube0c\ubaa8\ub4c8\uc744 \uc815\uc758\ud558\uace0 \ub098\uba74 \uc2e4\uc81c \ub514\ucf54\ub354 \ubaa8\ub378\uc744 \uad6c\ud604\ud560 \uc218\n\uc788\uac8c \ub429\ub2c8\ub2e4. \ub514\ucf54\ub354\uc5d0 \ub300\ud574\uc11c\ub294 \ub9e4 \uc2dc\uac04\ub9c8\ub2e4 \ubc30\uce58\ub97c \ud558\ub098\uc529 \uc218\ub3d9\uc73c\ub85c\n\uc81c\uacf5\ud558\ub824 \ud569\ub2c8\ub2e4. \uc774\ub294 \uc784\ubca0\ub529\ub41c \ub2e8\uc5b4 \ud150\uc11c\uc640 GRU \ucd9c\ub825\uc758 \ubaa8\uc591\uc774 \ub458 \ub2e4\n*(1, batch_size, hidden_size)* \ub77c\ub294 \uc758\ubbf8\uc785\ub2c8\ub2e4.\n\n**\uacc4\uc0b0 \uadf8\ub798\ud504:**\n\n   1) \ud604\uc7ac\uc758 \uc785\ub825 \ub2e8\uc5b4\uc5d0 \ub300\ud55c \uc784\ubca0\ub529\uc744 \uad6c\ud569\ub2c8\ub2e4.\n   2) \ubb34\ubc29\ud5a5 GRU\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4.\n   3) (2)\uc5d0\uc11c \uad6c\ud55c \ud604\uc7ac\uc758 GRU \ucd9c\ub825\uc744 \ubc14\ud0d5\uc73c\ub85c \uc5b4\ud150\uc158 \uac00\uc911\uce58\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n   4) \uc778\ucf54\ub354 \ucd9c\ub825\uc5d0 \uc5b4\ud150\uc158\uc744 \uacf1\ud558\uc5ec \uc0c8\ub85c\uc6b4 \"\uac00\uc911\uce58 \ud569\" \ubb38\ubc31 \ubca1\ud130\ub97c \uad6c\ud569\ub2c8\ub2e4.\n   5) Luong\uc758 \ub17c\ubb38\uc5d0 \ub098\uc628 \uc2dd 5\ub97c \uc774\uc6a9\ud558\uc5ec \uac00\uc911\uce58 \ubb38\ubc31 \ubca1\ud130\uc640 GRU \ucd9c\ub825\uc744 \uacb0\ud569\ud569\ub2c8\ub2e4.\n   6) Luong\uc758 \ub17c\ubb38\uc5d0 \ub098\uc628 \uc2dd 6\uc744 \uc774\uc6a9\ud558\uc5ec(softmax \uc5c6\uc774) \ub2e4\uc74c \ub2e8\uc5b4\ub97c \uc608\uce21\ud569\ub2c8\ub2e4.\n   7) \ucd9c\ub825\uacfc \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n**\uc785\ub825:**\n\n-  ``input_step``: \uc785\ub825 \uc2dc\ud000\uc2a4 \ubc30\uce58\uc5d0 \ub300\ud55c \ud55c \ub2e8\uc704 \uc2dc\uac04(\ud55c \ub2e8\uc5b4).\n   shape=\\ *(1, batch_size)*\n-  ``last_hidden``: GRU\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \ub808\uc774\uc5b4. shape=\\ *(n_layers x\n   num_directions, batch_size, hidden_size)*\n-  ``encoder_outputs``: \uc778\ucf54\ub354 \ubaa8\ub378\uc758 \ucd9c\ub825. shape=\\ *(max_length,\n   batch_size, hidden_size)*\n\n**\ucd9c\ub825:**\n\n-  ``output``: \uac01 \ub2e8\uc5b4\uac00 \ub514\ucf54\ub529\ub41c \uc2dc\ud000\uc2a4\uc5d0\uc11c \ub2e4\uc74c \ub2e8\uc5b4\ub85c \uc0ac\uc6a9\ub418\uc5c8\uc744\n   \ub54c \uc801\ud569\ud560 \ud655\ub960\uc744 \ub098\ud0c0\ub0b4\ub294 \uc815\uaddc\ud654\ub41c softmax \ud150\uc11c.\n   shape=\\ *(batch_size, voc.num_words)*\n-  ``hidden``: GRU\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc. shape=\\ *(n_layers x\n   num_directions, batch_size, hidden_size)*\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n        super(LuongAttnDecoderRNN, self).__init__()\n\n        # \ucc38\uc870\ub97c \ubcf4\uc874\ud574 \ub461\ub2c8\ub2e4\n        self.attn_model = attn_model\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout = dropout\n\n        # \ub808\uc774\uc5b4\ub97c \uc815\uc758\ud569\ub2c8\ub2e4\n        self.embedding = embedding\n        self.embedding_dropout = nn.Dropout(dropout)\n        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n        self.out = nn.Linear(hidden_size, output_size)\n\n        self.attn = Attn(attn_model, hidden_size)\n\n    def forward(self, input_step, last_hidden, encoder_outputs):\n        # \uc8fc\uc758: \ud55c \ub2e8\uc704 \uc2dc\uac04\uc5d0 \ub300\ud574 \ud55c \ub2e8\uacc4(\ub2e8\uc5b4)\ub9cc\uc744 \uc218\ud589\ud569\ub2c8\ub2e4\n        # \ud604\uc7ac\uc758 \uc785\ub825 \ub2e8\uc5b4\uc5d0 \ub300\ud55c \uc784\ubca0\ub529\uc744 \uad6c\ud569\ub2c8\ub2e4\n        embedded = self.embedding(input_step)\n        embedded = self.embedding_dropout(embedded)\n        # \ubb34\ubc29\ud5a5 GRU\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4\n        rnn_output, hidden = self.gru(embedded, last_hidden)\n        # \ud604\uc7ac\uc758 GRU \ucd9c\ub825\uc744 \ubc14\ud0d5\uc73c\ub85c \uc5b4\ud150\uc158 \uac00\uc911\uce58\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4\n        attn_weights = self.attn(rnn_output, encoder_outputs)\n        # \uc778\ucf54\ub354 \ucd9c\ub825\uc5d0 \uc5b4\ud150\uc158\uc744 \uacf1\ud558\uc5ec \uc0c8\ub85c\uc6b4 \"\uac00\uc911\uce58 \ud569\" \ubb38\ubc31 \ubca1\ud130\ub97c \uad6c\ud569\ub2c8\ub2e4\n        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n        # Luong\uc758 \ub17c\ubb38\uc5d0 \ub098\uc628 \uc2dd 5\ub97c \uc774\uc6a9\ud558\uc5ec \uac00\uc911\uce58 \ubb38\ubc31 \ubca1\ud130\uc640 GRU \ucd9c\ub825\uc744 \uacb0\ud569\ud569\ub2c8\ub2e4\n        rnn_output = rnn_output.squeeze(0)\n        context = context.squeeze(1)\n        concat_input = torch.cat((rnn_output, context), 1)\n        concat_output = torch.tanh(self.concat(concat_input))\n        # Luong\uc758 \ub17c\ubb38\uc5d0 \ub098\uc628 \uc2dd 6\uc744 \uc774\uc6a9\ud558\uc5ec \ub2e4\uc74c \ub2e8\uc5b4\ub97c \uc608\uce21\ud569\ub2c8\ub2e4\n        output = self.out(concat_output)\n        output = F.softmax(output, dim=1)\n        # \ucd9c\ub825\uacfc \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4\n        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ud504\ub85c\uc2dc\uc800 \uc815\uc758\ud558\uae30\n----------------------\n\nMasked loss\n~~~~~~~~~~~\n\n\uc6b0\ub9ac\ub294 \ud328\ub529\ub41c \uc2dc\ud000\uc2a4 \ubc30\uce58\ub97c \ub2e4\ub8e8\uae30 \ub54c\ubb38\uc5d0 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud560 \ub54c \ub2e8\uc21c\ud788 \ud150\uc11c\uc758\n\ubaa8\ub4e0 \uc6d0\uc18c\ub97c \uace0\ub824\ud560 \uc218\ub294 \uc5c6\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 ``maskNLLLoss`` \ub97c \uc815\uc758\ud558\uc5ec\n\ub514\ucf54\ub354\uc758 \ucd9c\ub825 \ud150\uc11c, \ubaa9\ud45c \ud150\uc11c, \uc774\uc9c4 \ub9c8\uc2a4\ud06c \ud150\uc11c\ub97c \ubc14\ud0d5\uc73c\ub85c \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\ub824\n\ud569\ub2c8\ub2e4. \uc774 \uc190\uc2e4 \ud568\uc218\uc5d0\uc11c\ub294 \ub9c8\uc2a4\ud06c \ud150\uc11c\uc758 *1* \uc5d0 \ub300\uc751\ud558\ub294 \uc6d0\uc18c\uc5d0 \ub300\ud55c \uc74c\uc758\n\ub85c\uadf8 \uc6b0\ub3c4 \uac12\uc758 \ud3c9\uade0\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def maskNLLLoss(inp, target, mask):\n    nTotal = mask.sum()\n    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n    loss = crossEntropy.masked_select(mask).mean()\n    loss = loss.to(device)\n    return loss, nTotal.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud55c \ubc88\uc758 \ud559\uc2b5 \ub2e8\uacc4\n~~~~~~~~~~~~~~~~~\n\n``train`` \ud568\uc218\uc5d0 \ud559\uc2b5\uc744 \ud55c \ub2e8\uacc4(\uc785\ub825 \ubc30\uce58 \ud55c \uac1c\uc5d0 \ub300\ud55c) \uc9c4\ud589\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc774\n\ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.\n\n\uc6b0\ub9ac\ub294 \uc218\ub834\uc774 \uc798 \ub418\ub3c4\ub85d \uba87 \uac00\uc9c0 \uc601\ub9ac\ud55c \uc804\ub7b5\uc744 \uc0ac\uc6a9\ud574\ubcf4\ub824 \ud569\ub2c8\ub2e4.\n\n-  \uccab \ubc88\uc9f8 \uc804\ub7b5\uc740 **teacher forcing** \uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc785\ub2c8\ub2e4. \uc774\ub294\n   ``teacher_forcing_ratio`` \ub85c \uc815\uc758\ub41c \ud655\ub960\uc5d0 \ub530\ub77c, \ub514\ucf54\ub354\uc758 \uc774\ubc88 \ub2e8\uacc4\n   \uc608\uce21\uac12 \ub300\uc2e0\uc5d0 \ud604\uc7ac\uc758 \ubaa9\ud45c \ub2e8\uc5b4\ub97c \ub514\ucf54\ub354\uc758 \ub2e4\uc74c \uc785\ub825 \uac12\uc73c\ub85c \ud65c\uc6a9\ud558\ub294\n   \uac83\uc785\ub2c8\ub2e4. \uc774 \uae30\ubc95\uc740 \ub514\ucf54\ub354\uc758 \ubcf4\uc870 \ubc14\ud034\ucc98\ub7fc \uc791\uc6a9\ud558\uc5ec \ud6a8\uc728\uc801\uc73c\ub85c \ud559\uc2b5\ub420 \uc218\n   \uc788\uac8c \ub3c4\uc640 \uc90d\ub2c8\ub2e4. \ud558\uc9c0\ub9cc teacher forcing \uae30\ubc95\uc740 \ucd94\ub860 \uacfc\uc815\uc5d0\uc11c \ubaa8\ub378\uc774\n   \ubd88\uc548\uc815 \ud574\uc9c0\ub3c4\ub85d \ud560 \uc218\ub3c4 \uc788\ub294\ub370, \uc774\ub294 \ub514\ucf54\ub354\uac00 \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c \uc790\uc2e0\uc758 \ucd9c\ub825\n   \uc2dc\ud000\uc2a4\ub97c \uc9c1\uc811 \ub9cc\ub4e4\uc5b4 \ubcfc \uae30\ud68c\ub97c \ucda9\ubd84\ud788 \uc81c\uacf5\ubc1b\uc9c0 \ubabb\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n   \ub530\ub77c\uc11c \uc6b0\ub9ac\ub294 ``teacher_forcing_ratio`` \ub97c \uc5b4\ub5bb\uac8c \uc124\uc815\ud574 \ub450\uc5c8\ub294\uc9c0\uc5d0\n   \uc8fc\uc758\ub97c \uae30\uc6b8\uc5ec\uc57c \ud558\uba70, \uc218\ub834\uc774 \ube68\ub9ac \ub418\uc5c8\ub2e4\uace0 \uc18d\uc544 \ub118\uc5b4\uac00\uc11c\ub294 \uc548 \ub429\ub2c8\ub2e4.\n\n-  \uc6b0\ub9ac\uac00 \uad6c\ud604\ud55c \ub450 \ubc88\uc9f8 \uc804\ub7b5\uc740 **gradient clipping** \uc785\ub2c8\ub2e4. \uc774\ub294 \uc18c\uc704\n   '\uadf8\ub77c\ub514\uc5b8\ud2b8 \ud3ed\ubc1c' \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \ub110\ub9ac \uc0ac\uc6a9\ub418\ub294 \uae30\ubc95\uc785\ub2c8\ub2e4. \ud575\uc2ec\uc740\n   \uadf8\ub77c\ub514\uc5b8\ud2b8\ub97c \ud074\ub9ac\ud551 \ud558\uac70\ub098 \uc784\uacc4\uac12\uc744 \ub460\uc73c\ub85c\uc368, \uadf8\ub77c\ub514\uc5b8\ud2b8\uac00 \uc9c0\uc218\n   \ud568\uc218\uc801\uc73c\ub85c \uc99d\uac00\ud558\uac70\ub098 \uc624\ubc84\ud50c\ub85c\ub97c \uc77c\uc73c\ud0a4\ub294(NaN) \uacbd\uc6b0\ub97c \ub9c9\uace0, \ube44\uc6a9 \ud568\uc218\uc758\n   \uae09\uaca9\ud55c \uacbd\uc0ac\ub97c \ud53c\ud558\uaca0\ub2e4\ub294 \uac83\uc785\ub2c8\ub2e4.\n\n.. figure:: /_static/img/chatbot/grad_clip.png\n   :align: center\n   :width: 60%\n   :alt: grad_clip\n\n\uadf8\ub9bc \ucd9c\ucc98: Goodfellow \ub4f1 \uc800. *Deep Learning*. 2016. https://www.deeplearningbook.org/\n\n**\uc791\uc5c5 \uc808\ucc28:**\n\n   1) \uc804\uccb4 \uc785\ub825 \ubc30\uce58\uc5d0 \ub300\ud558\uc5ec \uc778\ucf54\ub354\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4.\n   2) \ub514\ucf54\ub354\uc758 \uc785\ub825\uc744 SOS_token\ub85c, \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\ub85c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n   3) \uc785\ub825 \ubc30\uce58 \uc2dc\ud000\uc2a4\ub97c \ud55c \ubc88\uc5d0 \ud558\ub098\uc529 \ub514\ucf54\ub354\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ud569\ub2c8\ub2e4.\n   4) Teacher forcing\uc744 \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0, \ub514\ucf54\ub354\uc758 \ub2e4\uc74c \uc785\ub825\uc744 \ud604\uc7ac\uc758 \ubaa9\ud45c\ub85c \ub461\ub2c8\ub2e4. \uadf8\ub807\uc9c0 \uc54a\uc73c\uba74 \ub514\ucf54\ub354\uc758 \ub2e4\uc74c \uc785\ub825\uc744 \ud604\uc7ac \ub514\ucf54\ub354\uc758 \ucd9c\ub825\uc73c\ub85c \ub461\ub2c8\ub2e4.\n   5) \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0 \ub204\uc801\ud569\ub2c8\ub2e4.\n   6) \uc5ed\uc804\ud30c\ub97c \uc218\ud589\ud569\ub2c8\ub2e4.\n   7) \uadf8\ub77c\ub514\uc5b8\ud2b8\ub97c \ud074\ub9ac\ud551 \ud569\ub2c8\ub2e4.\n   8) \uc778\ucf54\ub354 \ubc0f \ub514\ucf54\ub354 \ubaa8\ub378\uc758 \ud328\ub7ec\ubbf8\ud130\ub97c \uac31\uc2e0\ud569\ub2c8\ub2e4.\n\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>PyTorch\uc758 RNN \ubaa8\ub4c8(``RNN``, ``LSTM``, ``GRU``)\uc740 \uc804\uccb4 \uc785\ub825 \uc2dc\ud000\uc2a4(\ub610\ub294\n  \uc2dc\ud000\uc2a4\uc758 \ubc30\uce58)\ub97c \ub2e8\uc21c\ud788 \ub123\uc5b4\uc8fc\uae30\ub9cc \ud558\uba74 \ub2e4\ub978 \ube44\uc21c\ud658 \ub808\uc774\uc5b4\ucc98\ub7fc \uc0ac\uc6a9\ud560 \uc218\n  \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 ``encoder`` \uc5d0\uc11c ``GRU`` \ub808\uc774\uc5b4\ub97c \uc774\ub7f0 \uc2dd\uc73c\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n  \uadf8 \uc548\uc774 \uc2e4\uc81c\ub85c \uc5b4\ub5bb\uac8c \ub418\uc5b4 \uc788\ub294\uc9c0\ub97c \uc0b4\ud3b4\ubcf4\uba74, \ub9e4 \uc2dc\uac04 \ub2e8\uacc4\ub9c8\ub2e4 \uc740\ub2c9 \uc0c1\ud0dc\ub97c\n  \uacc4\uc0b0\ud558\ub294 \ubc18\ubcf5 \ud504\ub85c\uc138\uc2a4\uac00 \uc874\uc7ac\ud569\ub2c8\ub2e4. \ub610 \ub2e4\ub978 \ubc29\ubc95\uc740, \uc774 \ubaa8\ub4c8\uc744 \ub9e4\ubc88 \ud55c \ub2e8\uc704\n  \uc2dc\uac04\ub9cc\ud07c \uc218\ud589\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uadf8 \uacbd\uc6b0\uc5d0\ub294 \uc6b0\ub9ac\uac00 ``decoder`` \ubaa8\ub378\uc744 \ub2e4\ub8f0\n  \ub54c\ucc98\ub7fc, \ud559\uc2b5 \uacfc\uc815\uc5d0\uc11c \uc218\ub3d9\uc73c\ub85c \uc2dc\ud000\uc2a4\uc5d0 \ub300\ud574 \ubc18\ubcf5 \uc791\uc5c5\uc744 \uc218\ud589\ud574 \uc8fc\uc5b4\uc57c\n  \ud569\ub2c8\ub2e4. \uc774 \ubaa8\ub4c8\uc5d0 \ub300\ud574 \ubaa8\ub378\uc758 \uac1c\ub150\uc744 \ud655\uc2e4\ud788 \uac16\uace0\ub9cc \uc788\ub2e4\uba74, \uc21c\ucc28 \ubaa8\ub378\uc744\n  \uad6c\ud604\ud558\ub294 \uac83\ub3c4 \ub9e4\uc6b0 \ub2e8\uc21c\ud560 \uac83\uc785\ub2c8\ub2e4.</p></div>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n\n    # \uc81c\ub85c \uadf8\ub77c\ub514\uc5b8\ud2b8\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    # device \uc635\uc158\uc744 \uc124\uc815\ud569\ub2c8\ub2e4\n    input_variable = input_variable.to(device)\n    lengths = lengths.to(device)\n    target_variable = target_variable.to(device)\n    mask = mask.to(device)\n\n    # \ubcc0\uc218\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\n    loss = 0\n    print_losses = []\n    n_totals = 0\n\n    # \uc778\ucf54\ub354\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4\n    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n\n    # \ucd08\uae30 \ub514\ucf54\ub354 \uc785\ub825\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4(\uac01 \ubb38\uc7a5\uc744 SOS \ub3c4\ud070\uc73c\ub85c \uc2dc\uc791\ud569\ub2c8\ub2e4)\n    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n    decoder_input = decoder_input.to(device)\n\n    # \ub514\ucf54\ub354\uc758 \ucd08\uae30 \uc740\ub2c9 \uc0c1\ud0dc\ub97c \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \uc0c1\ud0dc\ub85c \ub461\ub2c8\ub2e4\n    decoder_hidden = encoder_hidden[:decoder.n_layers]\n\n    # \uc774\ubc88 \ubc18\ubcf5\uc5d0\uc11c teacher forcing\uc744 \uc0ac\uc6a9\ud560\uc9c0\ub97c \uacb0\uc815\ud569\ub2c8\ub2e4\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    # \ubc30\uce58 \uc2dc\ud000\uc2a4\ub97c \ud55c \ubc88\uc5d0 \ud558\ub098\uc529 \ub514\ucf54\ub354\ub85c \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ud569\ub2c8\ub2e4\n    if use_teacher_forcing:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # Teacher forcing \uc0ac\uc6a9: \ub2e4\uc74c \uc785\ub825\uc744 \ud604\uc7ac\uc758 \ubaa9\ud45c\ub85c \ub461\ub2c8\ub2e4\n            decoder_input = target_variable[t].view(1, -1)\n            # \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0 \ub204\uc801\ud569\ub2c8\ub2e4\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n    else:\n        for t in range(max_target_len):\n            decoder_output, decoder_hidden = decoder(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            # Teacher forcing \ubbf8\uc0ac\uc6a9: \ub2e4\uc74c \uc785\ub825\uc744 \ub514\ucf54\ub354\uc758 \ucd9c\ub825\uc73c\ub85c \ub461\ub2c8\ub2e4\n            _, topi = decoder_output.topk(1)\n            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n            decoder_input = decoder_input.to(device)\n            # \uc190\uc2e4\uc744 \uacc4\uc0b0\ud558\uace0 \ub204\uc801\ud569\ub2c8\ub2e4\n            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n            loss += mask_loss\n            print_losses.append(mask_loss.item() * nTotal)\n            n_totals += nTotal\n\n    # \uc5ed\uc804\ud30c\ub97c \uc218\ud589\ud569\ub2c8\ub2e4\n    loss.backward()\n\n    # \uadf8\ub77c\ub514\uc5b8\ud2b8 \ud074\ub9ac\ud551: \uadf8\ub77c\ub514\uc5b8\ud2b8\ub97c \uc81c\uc790\ub9ac\uc5d0\uc11c \uc218\uc815\ud569\ub2c8\ub2e4\n    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n\n    # \ubaa8\ub378\uc758 \uac00\uc911\uce58\ub97c \uc218\uc815\ud569\ub2c8\ub2e4\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return sum(print_losses) / n_totals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \ub2e8\uacc4\n~~~~~~~~~\n\n\uc774\uc81c \ub9c8\uc9c0\ub9c9\uc73c\ub85c \uc804\uccb4 \ud559\uc2b5 \ud504\ub85c\uc2dc\uc800\uc640 \ub370\uc774\ud130\ub97c \ud558\ub098\ub85c \uc5ee\uc744 \ub54c\uac00\n\ub418\uc5c8\uc2b5\ub2c8\ub2e4. ``trainIters`` \ud568\uc218\ub294 \uc8fc\uc5b4\uc9c4 \ubaa8\ub378, optimizer, \ub370\uc774\ud130 \ub4f1\uc744\n\ud1a0\ub300\ub85c \ud559\uc2b5\uc744 ``n_iterations`` \ubc88\uc758 \ub2e8\uacc4\ub9cc\ud07c \uc9c4\ud589\ud558\ub294 \uc5ed\ud560\uc744 \ub2f4\ub2f9\ud569\ub2c8\ub2e4.\n\uc774 \ud568\uc218\ub294 \uc790\uae30 \uc790\uc2e0\uc744 \uc0b4 \uc124\uba85\ud558\uace0 \uc788\ub294 \ud3b8\uc778\ub370, \ubb34\uac70\uc6b4 \uc791\uc5c5\uc744 ``train``\n\ud568\uc218\uc5d0 \uc62e\uaca8 \ub193\uc558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n\n\ud55c \uac00\uc9c0 \uc8fc\uc758\ud560 \uc810\uc740 \uc6b0\ub9ac\uac00 \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub824 \ud560 \ub54c, \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\uc758\nstate_dicts (\ud328\ub7ec\ubbf8\ud130), optimizer\uc758 state_dicts, \uc190\uc2e4, \uc9c4\ud589 \ub2e8\uacc4 \uc218\n\ub4f1\uc744 tarball\ub85c \ub9cc\ub4e4\uc5b4 \uc800\uc7a5\ud55c\ub2e4\ub294 \uc810\uc785\ub2c8\ub2e4. \ubaa8\ub378\uc744 \uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c\n\uc800\uc7a5\ud558\uba74 checkpoint\uc5d0 \ub300\ud574 \uc544\uc8fc \ub192\uc740 \uc218\uc900\uc758 \uc720\uc5f0\uc131\uc744 \ud655\ubcf4\ud560 \uc218 \uc788\uac8c\n\ub429\ub2c8\ub2e4. Checkpoint\ub97c \ubd88\ub7ec\uc624\uace0 \ub098\uba74, \uc6b0\ub9ac\ub294 \ubaa8\ub378 \ud328\ub7ec\ubbf8\ud130\ub97c \uc774\uc6a9\ud558\uc5ec\n\uc608\uce21\uc744 \uc9c4\ud589\ud560 \uc218\ub3c4 \uc788\uace0, \uc774\uc804\uc5d0 \uba48\ucdc4\ub358 \ubd80\ubd84\ubd80\ud130 \ud559\uc2b5\uc744 \uacc4\uc18d  \uc9c4\ud589\ud560\n\uc218\ub3c4 \uc788\uac8c \ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n\n    # \uac01 \ub2e8\uacc4\uc5d0 \ub300\ud55c \ubc30\uce58\ub97c \uc77d\uc5b4\uc635\ub2c8\ub2e4\n    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n                      for _ in range(n_iteration)]\n\n    # \ucd08\uae30\ud654\n    print('Initializing ...')\n    start_iteration = 1\n    print_loss = 0\n    if loadFilename:\n        start_iteration = checkpoint['iteration'] + 1\n\n    # \ud559\uc2b5 \ub8e8\ud504\n    print(\"Training...\")\n    for iteration in range(start_iteration, n_iteration + 1):\n        training_batch = training_batches[iteration - 1]\n        # \ubc30\uce58\uc5d0\uc11c \uac01 \ud544\ub4dc\ub97c \uc77d\uc5b4\uc635\ub2c8\ub2e4\n        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n\n        # \ubc30\uce58\uc5d0 \ub300\ud574 \ud559\uc2b5\uc744 \ud55c \ub2e8\uacc4 \uc9c4\ud589\ud569\ub2c8\ub2e4\n        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n        print_loss += loss\n\n        # \uacbd\uacfc\ub97c \ucd9c\ub825\ud569\ub2c8\ub2e4\n        if iteration % print_every == 0:\n            print_loss_avg = print_loss / print_every\n            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n            print_loss = 0\n\n        # Checkpoint\ub97c \uc800\uc7a5\ud569\ub2c8\ub2e4\n        if (iteration % save_every == 0):\n            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n            if not os.path.exists(directory):\n                os.makedirs(directory)\n            torch.save({\n                'iteration': iteration,\n                'en': encoder.state_dict(),\n                'de': decoder.state_dict(),\n                'en_opt': encoder_optimizer.state_dict(),\n                'de_opt': decoder_optimizer.state_dict(),\n                'loss': loss,\n                'voc_dict': voc.__dict__,\n                'embedding': embedding.state_dict()\n            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00 \uc815\uc758\ud558\uae30\n-------------\n\n\ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\uace0 \ub098\uba74 \uc9c1\uc811 \ubd07\uacfc \ub300\ud654\ub97c \ub098\ub220\ubcf4\uace0 \uc2f6\uc5b4\uc9c8 \uac83\uc785\ub2c8\ub2e4. \uadf8\ub7ec\ub824\uba74\n\uba3c\uc800 \ubaa8\ub378\uc774 \uc778\ucf54\ub529\ub41c \uc785\ub825\uc744 \uc5b4\ub5bb\uac8c \ub514\ucf54\ub529\ud560\uc9c0\ub97c \uc815\uc758\ud574\uc918\uc57c \ud569\ub2c8\ub2e4.\n\n\ud0d0\uc695\uc801 \ub514\ucf54\ub529\n~~~~~~~~~~~~~\n\n\ud0d0\uc695\uc801 \ub514\ucf54\ub529(Greedy decoding)\uc740 \uc6b0\ub9ac\uac00 \ud559\uc2b5 \ub2e8\uacc4\uc5d0\uc11c teacher forcing\uc744\n\uc801\uc6a9\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c \uc0ac\uc6a9\ud55c \ub514\ucf54\ub529 \ubc29\ubc95\uc785\ub2c8\ub2e4. \ub2ec\ub9ac \ub9d0\ud558\uba74, \uac01 \ub2e8\uacc4\uc5d0 \ub300\ud574\n\ub2e8\uc21c\ud788 ``decoder_output`` \uc5d0\uc11c \uac00\uc7a5 \ub192\uc740 softmax\uac12\uc744 \uac16\ub294 \ub2e8\uc5b4\ub97c \uc120\ud0dd\ud558\ub294\n\ubc29\uc2dd\uc785\ub2c8\ub2e4. \uc774 \ub514\ucf54\ub529 \ubc29\ubc95\uc740 \ud55c \ubc88\uc758 \ub2e8\uacc4\uc5d0 \ub300\ud574\uc11c\ub294 \ucd5c\uc801\uc785\ub2c8\ub2e4.\n\n\uc6b0\ub9ac\ub294 \ud0d0\uc695\uc801 \ub514\ucf54\ub529 \uc5f0\uc0b0\uc744 \uc218\ud589\ud560 \uc218 \uc788\ub3c4\ub85d ``GreedySearchDecoder``\n\ud074\ub798\uc2a4\ub97c \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4. \uc218\ud589 \uacfc\uc815\uc5d0\uc11c \uc774 \ud074\ub798\uc2a4\uc758 \uc778\uc2a4\ud134\uc2a4\ub294 \ubaa8\uc591\uc774\n*(input_seq length, 1)* \uc778 \uc785\ub825 \uc2dc\ud000\uc2a4(``input_seq``), \uc870\uc885\ud560 \uc785\ub825\n\uae38\uc774(``input_length``) \ud150\uc11c, \uadf8\ub9ac\uace0 \uc751\ub2f5 \ubb38\uc7a5 \uae38\uc774\uc758 \uc81c\ud55c\uc744 \ub098\ud0c0\ub0b4\ub294\n``max_length`` \ub97c \uc785\ub825\uc73c\ub85c \ubc1b\uc2b5\ub2c8\ub2e4. \uc785\ub825 \uc2dc\ud000\uc11c\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \uacc4\uc0b0 \uadf8\ub798\ud504\uc5d0\n\uc758\ud574 \ud3c9\uac00\ub429\ub2c8\ub2e4.\n\n**\uacc4\uc0b0 \uadf8\ub798\ud504:**\n\n   1) \uc778\ucf54\ub354 \ubaa8\ub378\ub85c \uc785\ub825\uc744 \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ud569\ub2c8\ub2e4.\n   2) \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \ub808\uc774\uc5b4\uac00 \ub514\ucf54\ub354\uc758 \uccab \ubc88\uc9f8 \uc740\ub2c9 \ub808\uc774\uc5b4\uc758 \uc785\ub825\uc774 \ub418\ub3c4\ub85d \uc900\ube44\ud569\ub2c8\ub2e4.\n   3) \ub514\ucf54\ub354\uc758 \uccab \ubc88\uc9f8 \uc785\ub825\uc744 SOS_token\uc73c\ub85c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n   4) \ub514\ucf54\ub354\uac00 \ub2e8\uc5b4\ub97c \ub367\ubd99\uc5ec \ub098\uac08 \ud150\uc11c\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n   5) \ubc18\ubcf5\uc801\uc73c\ub85c \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \ud558\ub098\uc758 \ub2e8\uc5b4 \ud1a0\ud070\uc744 \ub514\ucf54\ub529\ud569\ub2c8\ub2e4.\n       a) \ub514\ucf54\ub354\ub85c\uc758 \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4.\n       b) \uac00\uc7a5 \uac00\ub2a5\uc131 \ub192\uc740 \ub2e8\uc5b4 \ud1a0\ud070\uacfc \uadf8 softmax \uc810\uc218\ub97c \uad6c\ud569\ub2c8\ub2e4.\n       c) \ud1a0\ud070\uacfc \uc810\uc218\ub97c \uae30\ub85d\ud569\ub2c8\ub2e4.\n       d) \ud604\uc7ac\uc758 \ud1a0\ud070\uc744 \ub514\ucf54\ub354\uc758 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc900\ube44\uc2dc\ud0b5\ub2c8\ub2e4.\n   6) \ub2e8\uc5b4 \ud1a0\ud070\uacfc \uc810\uc218\ub97c \ubaa8\uc544\uc11c \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GreedySearchDecoder(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(GreedySearchDecoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, input_seq, input_length, max_length):\n        # \uc778\ucf54\ub354 \ubaa8\ub378\ub85c \uc785\ub825\uc744 \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ud569\ub2c8\ub2e4\n        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n        # \uc778\ucf54\ub354\uc758 \ub9c8\uc9c0\ub9c9 \uc740\ub2c9 \ub808\uc774\uc5b4\uac00 \ub514\ucf54\ub354\uc758 \uccab \ubc88\uc9f8 \uc740\ub2c9 \ub808\uc774\uc5b4\uc758 \uc785\ub825\uc774 \ub418\ub3c4\ub85d \uc900\ube44\ud569\ub2c8\ub2e4\n        decoder_hidden = encoder_hidden[:decoder.n_layers]\n        # \ub514\ucf54\ub354\uc758 \uccab \ubc88\uc9f8 \uc785\ub825\uc744 SOS_token\uc73c\ub85c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\n        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n        # \ub514\ucf54\ub354\uac00 \ub2e8\uc5b4\ub97c \ub367\ubd99\uc5ec \ub098\uac08 \ud150\uc11c\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\n        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n        all_scores = torch.zeros([0], device=device)\n        # \ubc18\ubcf5\uc801\uc73c\ub85c \uac01 \ub2e8\uacc4\ub9c8\ub2e4 \ud558\ub098\uc758 \ub2e8\uc5b4 \ud1a0\ud070\uc744 \ub514\ucf54\ub529\ud569\ub2c8\ub2e4\n        for _ in range(max_length):\n            # \ub514\ucf54\ub354\ub85c\uc758 \ud3ec\uc6cc\ub4dc \ud328\uc2a4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4\n            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n            # \uac00\uc7a5 \uac00\ub2a5\uc131 \ub192\uc740 \ub2e8\uc5b4 \ud1a0\ud070\uacfc \uadf8 softmax \uc810\uc218\ub97c \uad6c\ud569\ub2c8\ub2e4\n            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n            # \ud1a0\ud070\uacfc \uc810\uc218\ub97c \uae30\ub85d\ud569\ub2c8\ub2e4\n            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n            # \ud604\uc7ac\uc758 \ud1a0\ud070\uc744 \ub514\ucf54\ub354\uc758 \ub2e4\uc74c \uc785\ub825\uc73c\ub85c \uc900\ube44\uc2dc\ud0b5\ub2c8\ub2e4(\ucc28\uc6d0\uc744 \uc99d\uac00\uc2dc\ucf1c\uc11c)\n            decoder_input = torch.unsqueeze(decoder_input, 0)\n        # \ub2e8\uc5b4 \ud1a0\ud070\uacfc \uc810\uc218\ub97c \ubaa8\uc544\uc11c \ubc18\ud658\ud569\ub2c8\ub2e4\n        return all_tokens, all_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub0b4 \ud14d\uc2a4\ud2b8 \ud3c9\uac00\ud558\uae30\n~~~~~~~~~~~~~~~~~~\n\n\uc774\uc81c \ub514\ucf54\ub529 \ubaa8\ub378\uc744 \uc815\uc758\ud588\uc73c\ub2c8, \ubb38\uc790\uc5f4\ub85c \ub41c \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ud3c9\uac00\ud558\ub294 \ud568\uc218\ub97c\n\uc791\uc131\ud574\ubcfc \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4. ``evaluate`` \ud568\uc218\uc5d0 \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ub0ae\uc740\n\ub808\ubca8\uc5d0\uc11c \uc5b4\ub5bb\uac8c \ucc98\ub9ac\ud560\uc9c0\uac00 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uba3c\uc800 \ubb38\uc7a5\uc744\n*batch_size==1* \uc774\uace0 \ub2e8\uc5b4 \uc778\ub371\uc2a4\ub85c \uad6c\uc131\ub41c \uc785\ub825 \ubc30\uce58 \ud615\ud0dc\ub85c \ub9cc\ub4ed\ub2c8\ub2e4.\n\uc774\ub97c \uc704\ud574 \ubb38\uc7a5\uc758 \uac01 \ub2e8\uc5b4\ub97c \uadf8\uc5d0 \ub300\uc751\ud558\ub294 \uc778\ub371\uc2a4\ub85c \ubcc0\ud658\ud558\uace0, \ucc28\uc6d0\uc744\n\ub4a4\uc9d1\uc5b4\uc11c \ubaa8\ub378\uc5d0 \ub9de\ub294 \uc785\ub825 \ud615\ud0dc\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \uae38\uc774\ub97c\n\uc800\uc7a5\ud558\uace0 \uc788\ub294 ``lengths`` \ud150\uc11c\ub3c4 \ub9cc\ub4ed\ub2c8\ub2e4. \uc774 \uacbd\uc6b0\uc5d0\ub294 ``lengths`` \uac00\n\uc2a4\uce7c\ub77c \uac12\uc774 \ub418\ub294\ub370, \uc6b0\ub9ac\ub294 \ud55c \ubc88\uc5d0 \ud55c \ubb38\uc7a5\ub9cc \ud3c9\uac00\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4(batch_size==1).\n\ub2e4\uc74c\uc73c\ub85c\ub294 ``GreedySearchDecoder`` \uc758 \uac1d\uccb4(``searcher``)\ub97c \uc774\uc6a9\ud558\uc5ec\n\uc751\ub2f5 \ubb38\uc7a5 \ud150\uc11c\ub97c \ub514\ucf54\ub529\ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc751\ub2f5 \uc778\ub371\uc2a4\ub97c \ub2e8\uc5b4\ub85c \ubcc0\ud658\ud558\uace0\n\ub514\ucf54\ub529\ub41c \ub2e8\uc5b4\uc758 \ub9ac\uc2a4\ud2b8\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n\n``evaluateInput`` \uc740 \uc6b0\ub9ac\uc758 \ucc57\ubd07\uc5d0 \ub300\ud55c \uc778\ud130\ud398\uc774\uc2a4 \uc5ed\ud560\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n\uc774\ub97c \ud638\ucd9c\ud558\uba74 \uc785\ub825 \ud14d\uc2a4\ud2b8 \ud544\ub4dc\uac00 \uc0dd\uc131\ub418\ub294\ub370, \uac70\uae30\uc5d0 \uc6b0\ub9ac\uc758 \uc9c8\uc758 \ubb38\uc7a5\uc744\n\uc785\ub825\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc785\ub825 \ubb38\uc7a5\uc744 \ud0c0\uc774\ud551\ud558\uace0 *\uc5d4\ud130* \ub97c \ub204\ub974\uba74, \uc785\ub825\ud55c\n\ud14d\uc2a4\ud2b8\uac00 \ud559\uc2b5 \ub370\uc774\ud130\uc640 \uac19\uc740 \ubc29\uc2dd\uc73c\ub85c \uc815\uaddc\ud654\ub418\uace0, \ucd5c\uc885\uc801\uc73c\ub85c\ub294 ``evaluate``\n\ud568\uc218\uc5d0 \uc785\ub825\uc73c\ub85c \uc81c\uacf5\ub418\uc5b4 \ub514\ucf54\ub529\ub41c \ucd9c\ub825 \ubb38\uc7a5\uc744 \uad6c\ud558\uac8c \ub429\ub2c8\ub2e4. \uc6b0\ub9ac\ub294\n\uc774\ub7ec\ud55c \uacfc\uc815\uc744 \uacc4\uc18d \ubc18\ubcf5\ud558\uba70, \uc774\ub97c \ud1b5\ud574 'q'\ub098 'quit'\ub97c \uc785\ub825\ud558\uae30 \uc804\uae4c\uc9c0\ub294\n\uacc4\uc18d \ucc44\ud305\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c, \ub9cc\uc57d \uc5b4\ud718\uc9d1\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc740 \ub2e8\uc5b4\ub97c \ud3ec\ud568\ud558\uace0 \uc788\ub294 \ubb38\uc7a5\uc774\n\uc785\ub825\ub418\ub354\ub77c\ub3c4 \uc774\ub97c \uc608\uc758 \ubc14\ub974\uac8c \ucc98\ub9ac\ud569\ub2c8\ub2e4. \uc989 \uc5d0\ub7ec \uba54\uc2dc\uc9c0\ub97c \ucd9c\ub825\ud558\uace0\n\uc0ac\uc6a9\uc790\uc5d0\uac8c \uc0c8\ub85c\uc6b4 \ubb38\uc7a5\uc744 \uc785\ub825\ud574\ub2ec\ub77c\uace0 \uc694\uad6c\uccad\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n    ### \uc785\ub825 \uc2dc\ud000\uc2a4\ub97c \ubc30\uce58 \ud615\ud0dc\ub85c \ub9cc\ub4ed\ub2c8\ub2e4\n    # \ub2e8\uc5b4 -> \uc778\ub371\uc2a4\n    indexes_batch = [indexesFromSentence(voc, sentence)]\n    # lengths \ud150\uc11c\ub97c \ub9cc\ub4ed\ub2c8\ub2e4\n    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n    # \ubc30\uce58\uc758 \ucc28\uc6d0\uc744 \ub4a4\uc9d1\uc5b4\uc11c \ubaa8\ub378\uc774 \uc0ac\uc6a9\ud558\ub294 \ud615\ud0dc\ub85c \ub9cc\ub4ed\ub2c8\ub2e4\n    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n    # \uc801\uc808\ud55c \ub514\ubc14\uc774\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4\n    input_batch = input_batch.to(device)\n    lengths = lengths.to(device)\n    # searcher\ub97c \uc774\uc6a9\ud558\uc5ec \ubb38\uc7a5\uc744 \ub514\ucf54\ub529\ud569\ub2c8\ub2e4\n    tokens, scores = searcher(input_batch, lengths, max_length)\n    # \uc778\ub371\uc2a4 -> \ub2e8\uc5b4\n    decoded_words = [voc.index2word[token.item()] for token in tokens]\n    return decoded_words\n\n\ndef evaluateInput(encoder, decoder, searcher, voc):\n    input_sentence = ''\n    while(1):\n        try:\n            # \uc785\ub825 \ubb38\uc7a5\uc744 \ubc1b\uc544\uc635\ub2c8\ub2e4\n            input_sentence = input('> ')\n            # \uc885\ub8cc \uc870\uac74\uc778\uc9c0 \uac80\uc0ac\ud569\ub2c8\ub2e4\n            if input_sentence == 'q' or input_sentence == 'quit': break\n            # \ubb38\uc7a5\uc744 \uc815\uaddc\ud654\ud569\ub2c8\ub2e4\n            input_sentence = normalizeString(input_sentence)\n            # \ubb38\uc7a5\uc744 \ud3c9\uac00\ud569\ub2c8\ub2e4\n            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n            # \uc751\ub2f5 \ubb38\uc7a5\uc744 \ud615\uc2dd\uc5d0 \ub9de\ucdb0 \ucd9c\ub825\ud569\ub2c8\ub2e4\n            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n            print('Bot:', ' '.join(output_words))\n\n        except KeyError:\n            print(\"Error: Encountered unknown word.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc218\ud589\ud558\uae30\n-------------\n\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c, \uc6b0\ub9ac\uc758 \ubaa8\ub378\uc744 \uc218\ud589\ud574 \ubcfc \uc2dc\uac04\uc785\ub2c8\ub2e4!\n\n\uc6b0\ub9ac\uac00 \ucc57\ubd07 \ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub54c\ub4e0 \ud14c\uc2a4\ud2b8\ud560 \ub54c\ub4e0, \uc6b0\ub9ac\ub294 \uac01\uac01\uc758 \uc778\ucf54\ub354 \ubc0f\n\ub514\ucf54\ub354 \ubaa8\ub378\uc744 \ucd08\uae30\ud654\ud574\uc918\uc57c \ud569\ub2c8\ub2e4. \ub2e4\uc74c \ube14\ub85d\uc5d0\uc11c\ub294 \uc6b0\ub9ac\uac00 \uc6d0\ud558\ub294\ub300\ub85c\n\uc124\uc815\uc744 \ub9de\ucd94\uace0, \ucc98\uc74c\ubd80\ud130 \uc2dc\uc791\ud560\uc9c0, \uc544\ub2c8\uba74 checkpoint\ub97c \ubd88\ub7ec\uc62c\uc9c0 \uc815\ud558\uace0,\n\ubaa8\ub378\uc744 \ube4c\ub4dc\ud558\uace0 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4. \uc131\ub2a5\uc744 \ucd5c\uc801\ud654\ud558\uae30 \uc704\ud574\uc11c\ub294 \ubaa8\ub378 \uc124\uc815\uc744\n\uc5ec\ub7ec\uac00\uc9c0\ub85c \ubc14\uafd4 \ubcf4\uba74\uc11c \ud14c\uc2a4\ud2b8\ud574\ubcf4\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ubaa8\ub378\uc744 \uc124\uc815\ud569\ub2c8\ub2e4\nmodel_name = 'cb_model'\nattn_model = 'dot'\n#attn_model = 'general'\n#attn_model = 'concat'\nhidden_size = 500\nencoder_n_layers = 2\ndecoder_n_layers = 2\ndropout = 0.1\nbatch_size = 64\n\n# \ubd88\ub7ec\uc62c checkpoint\ub97c \uc124\uc815\ud569\ub2c8\ub2e4. \ucc98\uc74c\ubd80\ud130 \uc2dc\uc791\ud560 \ub54c\ub294 None\uc73c\ub85c \ub461\ub2c8\ub2e4.\nloadFilename = None\ncheckpoint_iter = 4000\n#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n\n\n# loadFilename\uc774 \uc81c\uacf5\ub418\ub294 \uacbd\uc6b0\uc5d0\ub294 \ubaa8\ub378\uc744 \ubd88\ub7ec\uc635\ub2c8\ub2e4\nif loadFilename:\n    # \ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub54c\uc640 \uac19\uc740 \uae30\uae30\uc5d0\uc11c \ubd88\ub7ec\uc624\ub294 \uacbd\uc6b0\n    checkpoint = torch.load(loadFilename)\n    # GPU\uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc744 CPU\ub85c \ubd88\ub7ec\uc624\ub294 \uacbd\uc6b0\n    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n    encoder_sd = checkpoint['en']\n    decoder_sd = checkpoint['de']\n    encoder_optimizer_sd = checkpoint['en_opt']\n    decoder_optimizer_sd = checkpoint['de_opt']\n    embedding_sd = checkpoint['embedding']\n    voc.__dict__ = checkpoint['voc_dict']\n\n\nprint('Building encoder and decoder ...')\n# \ub2e8\uc5b4 \uc784\ubca0\ub529\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\nembedding = nn.Embedding(voc.num_words, hidden_size)\nif loadFilename:\n    embedding.load_state_dict(embedding_sd)\n# \uc778\ucf54\ub354 \ubc0f \ub514\ucf54\ub354 \ubaa8\ub378\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\nencoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\ndecoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\nif loadFilename:\n    encoder.load_state_dict(encoder_sd)\n    decoder.load_state_dict(decoder_sd)\n# \uc801\uc808\ud55c \ub514\ubc14\uc774\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4\nencoder = encoder.to(device)\ndecoder = decoder.to(device)\nprint('Models built and ready to go!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud559\uc2b5 \uc218\ud589\ud558\uae30\n~~~~~~~~~~~~~\n\n\ubaa8\ub378\uc744 \ud559\uc2b5\ud574\ubcf4\uace0 \uc2f6\ub2e4\uba74 \ub2e4\uc74c \ube14\ub85d\uc744 \uc218\ud589\ud558\uba74 \ub429\ub2c8\ub2e4.\n\n\uba3c\uc800 \ud559\uc2b5 \ud328\ub7ec\ubbf8\ud130\ub97c \uc124\uc815\ud558\uace0, optimizer\ub97c \ucd08\uae30\ud654\ud55c \ub4a4, \ub9c8\uc9c0\ub9c9\uc73c\ub85c ``trainIters``\n\ud568\uc218\ub97c \ud638\ucd9c\ud558\uc5ec \ud559\uc2b5 \ub2e8\uacc4\ub97c \uc9c4\ud589\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \ud559\uc2b5 \ubc0f \ucd5c\uc801\ud654 \uc124\uc815\nclip = 50.0\nteacher_forcing_ratio = 1.0\nlearning_rate = 0.0001\ndecoder_learning_ratio = 5.0\nn_iteration = 4000\nprint_every = 1\nsave_every = 500\n\n# Dropout \ub808\uc774\uc5b4\ub97c \ud559\uc2b5 \ubaa8\ub4dc\ub85c \ub461\ub2c8\ub2e4\nencoder.train()\ndecoder.train()\n\n# Optimizer\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\nprint('Building optimizers ...')\nencoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\ndecoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\nif loadFilename:\n    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n\n# cuda\uac00 \uc788\ub2e4\uba74 cuda\ub97c \uc124\uc815\ud569\ub2c8\ub2e4\nfor state in encoder_optimizer.state.values():\n    for k, v in state.items():\n        if isinstance(v, torch.Tensor):\n            state[k] = v.cuda()\n\nfor state in decoder_optimizer.state.values():\n    for k, v in state.items():\n        if isinstance(v, torch.Tensor):\n            state[k] = v.cuda()\n    \n# \ud559\uc2b5 \ub2e8\uacc4\ub97c \uc218\ud589\ud569\ub2c8\ub2e4\nprint(\"Starting Training!\")\ntrainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n           print_every, save_every, clip, corpus_name, loadFilename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00 \uc218\ud589\ud558\uae30\n~~~~~~~~~~~~~\n\n\uc5ec\ub7ec\ubd84\uc758 \ubaa8\ub378\uacfc \ucc44\ud305\uc744 \ud574\ubcf4\uace0 \uc2f6\ub2e4\uba74 \ub2e4\uc74c \ube14\ub85d\uc744 \uc218\ud589\ud558\uba74 \ub429\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Dropout \ub808\uc774\uc5b4\ub97c \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\ud569\ub2c8\ub2e4\nencoder.eval()\ndecoder.eval()\n\n# \ud0d0\uc0c9 \ubaa8\ub4c8\uc744 \ucd08\uae30\ud654\ud569\ub2c8\ub2e4\nsearcher = GreedySearchDecoder(encoder, decoder)\n\n# \ucc44\ud305\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4 (\ub2e4\uc74c \uc904\uc758 \uc8fc\uc11d\uc744 \uc81c\uac70\ud558\uba74 \uc2dc\uc791\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4)\n# evaluateInput(encoder, decoder, searcher, voc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub9fa\uc74c\ub9d0\n------\n\n\uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc774\uac83\uc73c\ub85c \ub9c8\ubb34\ub9ac\ud558\uaca0\uc2b5\ub2c8\ub2e4. \ucd95\ud558\ud569\ub2c8\ub2e4! \uc5ec\ub7ec\ubd84\uc740 \uc774\uc81c \uc0dd\uc131\n\ucc57\ubd07 \ubaa8\ub378\uc744 \ub9cc\ub4e4\uae30 \uc704\ud55c \uae30\ucd08 \uc9c0\uc2dd\uc744 \uc2b5\ub4dd\ud588\uc2b5\ub2c8\ub2e4. \ub9cc\uc57d \uc880 \ub354 \uad00\uc2ec\uc774 \uc788\ub2e4\uba74\n\ubaa8\ub378\uc774\ub098 \ud559\uc2b5 \ud328\ub7ec\ubbf8\ud130\ub97c \uc218\uc815\ud574 \ubcf4\uba74\uc11c, \ud639\uc740 \ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub370\uc774\ud130\ub97c \ubc14\uafd4\n\ubcf4\uba74\uc11c \ucc57\ubd07\uc758 \ud589\ub3d9\uc744 \uc218\uc815\ud574\ubcfc \uc218 \uc788\uc744 \uac83\uc785\ub2c8\ub2e4.\n\n\uadf8 \uc678\uc5d0\ub3c4 \ub525\ub7ec\ub2dd\uc758 \uba4b\uc9c4 \ud65c\uc6a9 \uc608\uc5d0 \ub300\ud55c PyTorch \ud29c\ud1a0\ub9ac\uc5bc\uc774 \uc788\uc73c\ub2c8 \ud55c \ubc88\n\ud655\uc778\ud574 \ubcf4\uae30 \ubc14\ub78d\ub2c8\ub2e4!\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}