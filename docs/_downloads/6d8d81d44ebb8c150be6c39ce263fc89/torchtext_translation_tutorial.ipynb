{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTorchText\ub85c \uc5b8\uc5b4 \ubc88\uc5ed\ud558\uae30\n===================================\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 ``torchtext`` \uc758 \uc720\uc6a9\ud55c \uc5ec\ub7ec \ud074\ub798\uc2a4\ub4e4\uacfc \uc2dc\ud000\uc2a4 \ud22c \uc2dc\ud000\uc2a4(sequence-to-sequence, seq2seq)\ubaa8\ub378\uc744 \ud1b5\ud574\n\uc601\uc5b4\uc640 \ub3c5\uc77c\uc5b4 \ubb38\uc7a5\ub4e4\uc774 \ud3ec\ud568\ub41c \uc720\uba85\ud55c \ub370\uc774\ud130 \uc14b\uc744 \uc774\uc6a9\ud574\uc11c \ub3c5\uc77c\uc5b4 \ubb38\uc7a5\uc744 \uc601\uc5b4\ub85c \ubc88\uc5ed\ud574 \ubcfc \uac83\uc785\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc740 \nPyTorch \ucee4\ubba4\ub2c8\ud2f0 \uba64\ubc84\uc778 `Ben Trevett <https://github.com/bentrevett>`__ \uc774 \uc791\uc131\ud55c\n`\ud29c\ud1a0\ub9ac\uc5bc <https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb>`__ \uc5d0 \uae30\ucd08\ud558\uace0 \uc788\uc73c\uba70\n`Seth Weidman <https://github.com/SethHWeidman/>`__ \uc774 Ben\uc758 \ud5c8\ub77d\uc744 \ubc1b\uace0 \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \ud1b5\ud574 \uc5ec\ub7ec\ubd84\uc740 \ub2e4\uc74c\uacfc \uac19\uc740 \uac83\uc744 \ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4:\n\n- ``torchtext`` \uc758 \uc544\ub798\uc640 \uac19\uc740 \uc720\uc6a9\ud55c \ud074\ub798\uc2a4\ub4e4\uc744 \ud1b5\ud574 \ubb38\uc7a5\ub4e4\uc744 NLP\ubaa8\ub378\ub9c1\uc5d0 \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294 \ud615\ud0dc\ub85c \uc804\ucc98\ub9ac\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4:\n    - `TranslationDataset <https://torchtext.readthedocs.io/en/latest/datasets.html#torchtext.datasets.TranslationDataset>`__\n    - `Field <https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Field>`__\n    - `BucketIterator <https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.BucketIterator>`__\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Field` \uc640 `TranslationDataset`\n----------------\n``torchtext`` \uc5d0\ub294 \uc5b8\uc5b4 \ubcc0\ud658 \ubaa8\ub378\uc744 \ub9cc\ub4e4\ub54c \uc27d\uac8c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ub370\uc774\ud130\uc14b\uc744 \ub9cc\ub4e4\uae30 \uc801\ud569\ud55c \ub2e4\uc591\ud55c \ub3c4\uad6c\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\uadf8 \uc911\uc5d0\uc11c\ub3c4 \uc911\uc694\ud55c \ud074\ub798\uc2a4 \uc911 \ud558\ub098\uc778 `Field <https://github.com/pytorch/text/blob/master/torchtext/data/field.py#L64>`__ \ub294\n\uac01 \ubb38\uc7a5\uc774 \uc5b4\ub5bb\uac8c \uc804\ucc98\ub9ac\ub418\uc5b4\uc57c \ud558\ub294\uc9c0 \uc9c0\uc815\ud558\uba70, \ub610 \ub2e4\ub978 \uc911\uc694\ud55c \ud074\ub798\uc2a4\ub85c\ub294 `TranslationDataset` \uc774 \uc788\uc2b5\ub2c8\ub2e4. \n``torchtext`` \uc5d0\ub294 \uc774 \uc678\uc5d0\ub3c4 \ube44\uc2b7\ud55c \ub370\uc774\ud130\uc14b\ub4e4\uc774 \uc788\ub294\ub370, \uc774\ubc88 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 `Multi30k dataset <https://github.com/multi30k/dataset>`__ \uc744 \uc0ac\uc6a9\ud560 \uac83\uc785\ub2c8\ub2e4.\n\uc774 \ub370\uc774\ud130 \uc14b\uc740 \ud3c9\uade0 \uc57d 13\uac1c\uc758 \ub2e8\uc5b4\ub85c \uad6c\uc131\ub41c \uc57d \uc0bc\ub9cc \uac1c\uc758 \ubb38\uc7a5\uc744 \uc601\uc5b4\uc640 \ub3c5\uc77c\uc5b4 \ub450 \uc5b8\uc5b4\ub85c \ud3ec\ud568\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n\ucc38\uace0 : \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\uc758 \ud1a0\ud070\ud654(tokenization)\uc5d0\ub294 `Spacy <https://spacy.io>`__ \uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\nSpacy\ub294 \uc601\uc5b4 \uc774 \uc678\uc758 \ub2e4\ub978 \uc5b8\uc5b4\uc5d0 \ub300\ud55c \uac15\ub825\ud55c \ud1a0\ud070\ud654 \uae30\ub2a5\uc744 \uc81c\uacf5\ud558\uae30 \ub54c\ubb38\uc5d0 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. ``torchtext`` \ub294\n`basic_english`` \ud1a0\ud06c\ub098\uc774\uc800\ub97c \uc81c\uacf5\ud560 \ubfd0 \uc544\ub2c8\ub77c \uc601\uc5b4\uc5d0 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ub2e4\ub978 \ud1a0\ud06c\ub098\uc774\uc800\ub4e4(\uc608\ucee8\ub370\n`Moses <https://bitbucket.org/luismsgomes/mosestokenizer/src/default/>`__ )\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4\ub9cc, \uc5b8\uc5b4 \ubc88\uc5ed\uc744 \uc704\ud574\uc11c\ub294 \ub2e4\uc591\ud55c \uc5b8\uc5b4\ub97c\n\ub2e4\ub8e8\uc5b4\uc57c \ud558\uae30 \ub54c\ubb38\uc5d0 Spacy\uac00 \uac00\uc7a5 \uc801\ud569\ud569\ub2c8\ub2e4.\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \uc2e4\ud589\ud558\ub824\uba74, \uc6b0\uc120 ``pip`` \ub098 ``conda`` \ub85c ``spacy`` \ub97c \uc124\uce58\ud558\uc138\uc694. \uadf8 \ub2e4\uc74c,\nSpacy \ud1a0\ud06c\ub098\uc774\uc800\uac00 \uc4f8 \uc601\uc5b4\uc640 \ub3c5\uc77c\uc5b4\uc5d0 \ub300\ud55c \ub370\uc774\ud130\ub97c \ub2e4\uc6b4\ub85c\ub4dc \ubc1b\uc2b5\ub2c8\ub2e4.\n\n::\n\n   python -m spacy download en\n   python -m spacy download de\n\nSpacy\uac00 \uc124\uce58\ub418\uc5b4 \uc788\ub2e4\uba74, \ub2e4\uc74c \ucf54\ub4dc\ub294 ``TranslationDataset`` \uc5d0 \uc788\ub294 \uac01 \ubb38\uc7a5\uc744 ``Field`` \uc5d0 \uc815\uc758\ub41c\n\ub0b4\uc6a9\uc744 \uae30\ubc18\uc73c\ub85c \ud1a0\ud070\ud654\ud560 \uac83\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import Multi30k\nfrom torchtext.data import Field, BucketIterator\n\nSRC = Field(tokenize = \"spacy\",\n            tokenizer_language=\"de\",\n            init_token = '<sos>',\n            eos_token = '<eos>',\n            lower = True)\n\nTRG = Field(tokenize = \"spacy\",\n            tokenizer_language=\"en\",\n            init_token = '<sos>',\n            eos_token = '<eos>',\n            lower = True)\n\ntrain_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n                                                    fields = (SRC, TRG))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774\uc81c ``train_data`` \ub97c \uc815\uc758\ud588\uc73c\ub2c8, ``torchtext`` \uc758 ``Field`` \uc5d0 \uc788\ub294 \uc5c4\uccad\ub098\uac8c \uc720\uc6a9\ud55c \uae30\ub2a5\uc744\n\ubcf4\uac8c \ub420 \uac83\uc785\ub2c8\ub2e4 : \ubc14\ub85c ``build_vovab`` \uba54\uc18c\ub4dc(method)\ub85c \uac01 \uc5b8\uc5b4\uc640 \uc5f0\uad00\ub41c \uc5b4\ud718\ub4e4\uc744 \ub9cc\ub4e4\uc5b4 \ub0bc \uac83\uc785\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\nTRG.build_vocab(train_data, min_freq = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc704 \ucf54\ub4dc\uac00 \uc2e4\ud589\ub418\uba74, ``SRC.vocab.stoi`` \ub294 \uc5b4\ud718\uc5d0 \ud574\ub2f9\ud558\ub294 \ud1a0\ud070\uc744 \ud0a4\ub85c, \uad00\ub828\ub41c \uc0c9\uc778\uc744 \uac12\uc73c\ub85c \uac00\uc9c0\ub294\n\uc0ac\uc804(dict)\uc774 \ub429\ub2c8\ub2e4. ``SRC.vocab.itos`` \uc5ed\uc2dc \uc0ac\uc804(dict)\uc774\uc9c0\ub9cc, \ud0a4\uc640 \uac12\uc774 \uc11c\ub85c \ubc18\ub300\uc785\ub2c8\ub2e4. \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294\n\uadf8\ub2e4\uc9c0 \uc911\uc694\ud558\uc9c0 \uc54a\uc740 \ub0b4\uc6a9\uc774\uc9c0\ub9cc, \uc774\ub7f0 \ud2b9\uc131\uc740 \ub2e4\ub978 \uc790\uc5f0\uc5b4 \ucc98\ub9ac \ub4f1\uc5d0\uc11c \uc720\uc6a9\ud558\uac8c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``BucketIterator``\n----------------\n\ub9c8\uc9c0\ub9c9\uc73c\ub85c \uc0ac\uc6a9\ud574 \ubcfc ``torchtext`` \uc5d0 \ud2b9\ud654\ub41c \uae30\ub2a5\uc740 \ubc14\ub85c ``BucketIterator`` \uc785\ub2c8\ub2e4.\n\uccab \ubc88\uc9f8 \uc778\uc790\ub85c ``TranslationDataset`` \uc744 \uc804\ub2ec\ubc1b\uae30 \ub54c\ubb38\uc5d0 \uc0ac\uc6a9\ud558\uae30\uac00 \uc27d\uc2b5\ub2c8\ub2e4. \ubb38\uc11c\uc5d0\uc11c\ub3c4 \ubcfc \uc218 \uc788\ub4ef\n\uc774 \uae30\ub2a5\uc740 \ube44\uc2b7\ud55c \uae38\uc774\uc758 \uc608\uc81c\ub4e4\uc744 \ubb36\uc5b4\uc8fc\ub294 \ubc18\ubcf5\uc790(iterator)\ub97c \uc815\uc758\ud569\ub2c8\ub2e4. \uac01\uac01\uc758 \uc0c8\ub85c\uc6b4 \uc5d0\ud3ec\ud06c(epoch)\ub9c8\ub2e4\n\uc0c8\ub85c \uc11e\uc778 \uacb0\uacfc\ub97c \ub9cc\ub4dc\ub294\ub370 \ud544\uc694\ud55c \ud328\ub529\uc758 \uc218\ub97c \ucd5c\uc18c\ud654 \ud569\ub2c8\ub2e4. \ubc84\ucf00\ud305 \uacfc\uc815\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 \uc800\uc7a5 \uacf5\uac04\uc744 \ud55c\ubc88 \uc0b4\ud3b4\ubcf4\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nBATCH_SIZE = 128\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train_data, valid_data, test_data),\n    batch_size = BATCH_SIZE,\n    device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ubc18\ubcf5\uc790\ub4e4\uc740 ``DataLoader`` \uc640 \ub9c8\ucc2c\uac00\uc9c0\ub85c \ud638\ucd9c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub798 ``train`` \uacfc \n``evaluation`` \ud568\uc218\uc5d0\uc11c \ubcf4\uba74, \ub2e4\uc74c\uacfc \uac19\uc774 \uac04\ub2e8\ud788 \ud638\ucd9c\ud560 \uc218 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4 :\n::\n\n   for i, batch in enumerate(iterator):\n\n\uac01 ``batch`` \ub294 ``src`` \uc640 ``trg`` \uc18d\uc131\uc744 \uac00\uc9c0\uac8c \ub429\ub2c8\ub2e4.\n\n::\n\n   src = batch.src\n   trg = batch.trg\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``nn.Module`` \uacfc ``Optimizer`` \uc815\uc758\ud558\uae30\n----------------\n\ub300\ubd80\ubd84\uc740 ``torchtext`` \uac00 \uc54c\uc544\uc11c \ud574\uc90d\ub2c8\ub2e4 : \ub370\uc774\ud130\uc14b\uc774 \ub9cc\ub4e4\uc5b4\uc9c0\uace0 \ubc18\ubcf5\uc790\uac00 \uc815\uc758\ub418\uba74, \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\n\uc6b0\ub9ac\uac00 \ud574\uc57c \ud560 \uc77c\uc774\ub77c\uace0\ub294 \uadf8\uc800 ``nn.Module`` \uc640 ``Optimizer`` \ub97c \ubaa8\ub378\ub85c\uc11c \uc815\uc758\ud558\uace0 \ud6c8\ub828\uc2dc\ud0a4\ub294 \uac83\uc774 \uc804\ubd80\uc785\ub2c8\ub2e4.\n\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc740 `\uc774\uacf3 <https://arxiv.org/abs/1409.0473>`__ \uc5d0\uc11c \uc124\uba85\ud558\uace0 \uc788\ub294 \uad6c\uc870\ub97c \ub530\ub974\uace0 \uc788\uc73c\uba70,\n\ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 `\uc5ec\uae30 <https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb>`__ \n\ub97c \ucc38\uace0\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\n\n\ucc38\uace0 : \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc740 \uc5b8\uc5b4 \ubc88\uc5ed\uc744 \uc704\ud574 \uc0ac\uc6a9\ud560 \uc608\uc2dc \ubaa8\ub378\uc785\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc740\n\uc774 \uc791\uc5c5\uc5d0 \uc801\ub2f9\ud55c \ud45c\uc900 \ubaa8\ub378\uc774\uae30 \ub54c\ubb38\uc774\uc9c0, \ubc88\uc5ed\uc5d0 \uc801\ud569\ud55c \ubaa8\ub378\uc774\uae30 \ub54c\ubb38\uc740 \uc544\ub2d9\ub2c8\ub2e4. \uc5ec\ub7ec\ubd84\uc774 \ucd5c\uc2e0 \uae30\uc220 \ud2b8\ub80c\ub4dc\ub97c\n\uc798 \ub530\ub77c\uac00\uace0 \uc788\ub2e4\uba74 \uc798 \uc544\uc2dc\uaca0\uc9c0\ub9cc, \ud604\uc7ac \ubc88\uc5ed\uc5d0\uc11c \uac00\uc7a5 \ub6f0\uc5b4\ub09c \ubaa8\ub378\uc740 Transformers\uc785\ub2c8\ub2e4. PyTorch\uac00\nTransformer \ub808\uc774\uc5b4\ub97c \uad6c\ud604\ud55c \ub0b4\uc6a9\uc740 `\uc5ec\uae30 <https://pytorch.org/docs/stable/nn.html#transformer-layers>`__\n\uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc73c\uba70 \uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc758 \ubaa8\ub378\uc774 \uc0ac\uc6a9\ud558\ub294 \"attention\" \uc740 Transformer \ubaa8\ub378\uc5d0\uc11c \uc81c\uc548\ud558\ub294\n\uba40\ud2f0 \ud5e4\ub4dc \uc140\ud504 \uc5b4\ud150\uc158(multi-headed self-attention) \uacfc\ub294 \ub2e4\ub974\ub2e4\ub294 \uc810\uc744 \uc54c\ub824\ub4dc\ub9bd\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\nfrom typing import Tuple\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch import Tensor\n\n\nclass Encoder(nn.Module):\n    def __init__(self,\n                 input_dim: int,\n                 emb_dim: int,\n                 enc_hid_dim: int,\n                 dec_hid_dim: int,\n                 dropout: float):\n        super().__init__()\n\n        self.input_dim = input_dim\n        self.emb_dim = emb_dim\n        self.enc_hid_dim = enc_hid_dim\n        self.dec_hid_dim = dec_hid_dim\n        self.dropout = dropout\n\n        self.embedding = nn.Embedding(input_dim, emb_dim)\n\n        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n\n        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self,\n                src: Tensor) -> Tuple[Tensor]:\n\n        embedded = self.dropout(self.embedding(src))\n\n        outputs, hidden = self.rnn(embedded)\n\n        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n\n        return outputs, hidden\n\n\nclass Attention(nn.Module):\n    def __init__(self,\n                 enc_hid_dim: int,\n                 dec_hid_dim: int,\n                 attn_dim: int):\n        super().__init__()\n\n        self.enc_hid_dim = enc_hid_dim\n        self.dec_hid_dim = dec_hid_dim\n\n        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n\n        self.attn = nn.Linear(self.attn_in, attn_dim)\n\n    def forward(self,\n                decoder_hidden: Tensor,\n                encoder_outputs: Tensor) -> Tensor:\n\n        src_len = encoder_outputs.shape[0]\n\n        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n\n        energy = torch.tanh(self.attn(torch.cat((\n            repeated_decoder_hidden,\n            encoder_outputs),\n            dim = 2)))\n\n        attention = torch.sum(energy, dim=2)\n\n        return F.softmax(attention, dim=1)\n\n\nclass Decoder(nn.Module):\n    def __init__(self,\n                 output_dim: int,\n                 emb_dim: int,\n                 enc_hid_dim: int,\n                 dec_hid_dim: int,\n                 dropout: int,\n                 attention: nn.Module):\n        super().__init__()\n\n        self.emb_dim = emb_dim\n        self.enc_hid_dim = enc_hid_dim\n        self.dec_hid_dim = dec_hid_dim\n        self.output_dim = output_dim\n        self.dropout = dropout\n        self.attention = attention\n\n        self.embedding = nn.Embedding(output_dim, emb_dim)\n\n        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n\n        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n\n        self.dropout = nn.Dropout(dropout)\n\n\n    def _weighted_encoder_rep(self,\n                              decoder_hidden: Tensor,\n                              encoder_outputs: Tensor) -> Tensor:\n\n        a = self.attention(decoder_hidden, encoder_outputs)\n\n        a = a.unsqueeze(1)\n\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n\n        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n\n        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n\n        return weighted_encoder_rep\n\n\n    def forward(self,\n                input: Tensor,\n                decoder_hidden: Tensor,\n                encoder_outputs: Tensor) -> Tuple[Tensor]:\n\n        input = input.unsqueeze(0)\n\n        embedded = self.dropout(self.embedding(input))\n\n        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n                                                          encoder_outputs)\n\n        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n\n        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n\n        embedded = embedded.squeeze(0)\n        output = output.squeeze(0)\n        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n\n        output = self.out(torch.cat((output,\n                                     weighted_encoder_rep,\n                                     embedded), dim = 1))\n\n        return output, decoder_hidden.squeeze(0)\n\n\nclass Seq2Seq(nn.Module):\n    def __init__(self,\n                 encoder: nn.Module,\n                 decoder: nn.Module,\n                 device: torch.device):\n        super().__init__()\n\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                teacher_forcing_ratio: float = 0.5) -> Tensor:\n\n        batch_size = src.shape[1]\n        max_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n\n        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n\n        encoder_outputs, hidden = self.encoder(src)\n\n        # \ub514\ucf54\ub354\ub85c\uc758 \uccab \ubc88\uc9f8 \uc785\ub825\uc740 <sos> \ud1a0\ud070\uc785\ub2c8\ub2e4.\n        output = trg[0,:]\n\n        for t in range(1, max_len):\n            output, hidden = self.decoder(output, hidden, encoder_outputs)\n            outputs[t] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.max(1)[1]\n            output = (trg[t] if teacher_force else top1)\n\n        return outputs\n\n\nINPUT_DIM = len(SRC.vocab)\nOUTPUT_DIM = len(TRG.vocab)\n# ENC_EMB_DIM = 256\n# DEC_EMB_DIM = 256\n# ENC_HID_DIM = 512\n# DEC_HID_DIM = 512\n# ATTN_DIM = 64\n# ENC_DROPOUT = 0.5\n# DEC_DROPOUT = 0.5\n\nENC_EMB_DIM = 32\nDEC_EMB_DIM = 32\nENC_HID_DIM = 64\nDEC_HID_DIM = 64\nATTN_DIM = 8\nENC_DROPOUT = 0.5\nDEC_DROPOUT = 0.5\n\nenc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n\nattn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n\nmodel = Seq2Seq(enc, dec, device).to(device)\n\n\ndef init_weights(m: nn.Module):\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        else:\n            nn.init.constant_(param.data, 0)\n\n\nmodel.apply(init_weights)\n\noptimizer = optim.Adam(model.parameters())\n\n\ndef count_parameters(model: nn.Module):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ucc38\uace0 : \uc5b8\uc5b4 \ubc88\uc5ed\uc758 \uc131\ub2a5 \uc810\uc218\ub97c \uae30\ub85d\ud558\ub824\uba74, ``nn.CrossEntropyLoss`` \ud568\uc218\uac00 \ub2e8\uc21c\ud55c\n\ud328\ub529\uc744 \ucd94\uac00\ud558\ub294 \ubd80\ubd84\uc744 \ubb34\uc2dc\ud560 \uc218 \uc788\ub3c4\ub85d \ud574\ub2f9 \uc0c9\uc778\ub4e4\uc744 \uc54c\ub824\uc918\uc57c \ud569\ub2c8\ub2e4.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub9c8\uc9c0\ub9c9\uc73c\ub85c \uc774 \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\uace0 \ud3c9\uac00\ud569\ub2c8\ub2e4 :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\nimport time\n\n\ndef train(model: nn.Module,\n          iterator: BucketIterator,\n          optimizer: optim.Optimizer,\n          criterion: nn.Module,\n          clip: float):\n\n    model.train()\n\n    epoch_loss = 0\n\n    for _, batch in enumerate(iterator):\n\n        src = batch.src\n        trg = batch.trg\n\n        optimizer.zero_grad()\n\n        output = model(src, trg)\n\n        output = output[1:].view(-1, output.shape[-1])\n        trg = trg[1:].view(-1)\n\n        loss = criterion(output, trg)\n\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    return epoch_loss / len(iterator)\n\n\ndef evaluate(model: nn.Module,\n             iterator: BucketIterator,\n             criterion: nn.Module):\n\n    model.eval()\n\n    epoch_loss = 0\n\n    with torch.no_grad():\n\n        for _, batch in enumerate(iterator):\n\n            src = batch.src\n            trg = batch.trg\n\n            output = model(src, trg, 0) #turn off teacher forcing\n\n            output = output[1:].view(-1, output.shape[-1])\n            trg = trg[1:].view(-1)\n\n            loss = criterion(output, trg)\n\n            epoch_loss += loss.item()\n\n    return epoch_loss / len(iterator)\n\n\ndef epoch_time(start_time: int,\n               end_time: int):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs\n\n\nN_EPOCHS = 10\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n\n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, valid_iterator, criterion)\n\n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n\ntest_loss = evaluate(model, test_iterator, criterion)\n\nprint(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub2e4\uc74c \ub2e8\uacc4\n--------------\n\n- ``torchtext`` \ub97c \uc0ac\uc6a9\ud55c Ben Trevett\uc758 \ud29c\ud1a0\ub9ac\uc5bc\uc744 `\uc774\uacf3 <https://github.com/bentrevett/>`__ \uc5d0\uc11c \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n- ``nn.Transformer`` \uc640 ``torchtext`` \uc758 \ub2e4\ub978 \uae30\ub2a5\ub4e4\uc744 \uc774\uc6a9\ud55c \ub2e4\uc74c \ub2e8\uc5b4 \uc608\uce21\uc744 \ud1b5\ud55c \uc5b8\uc5b4 \ubaa8\ub378\ub9c1 \ud29c\ud1a0\ub9ac\uc5bc\uc744 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\uc0b4\ud3b4\ubcf4\uc138\uc694."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}