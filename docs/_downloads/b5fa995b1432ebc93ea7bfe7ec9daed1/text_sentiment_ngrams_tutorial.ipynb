{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTorchText\ub85c \ud14d\uc2a4\ud2b8 \ubd84\ub958\ud558\uae30\n==================================\n**\ubc88\uc5ed**: `\uae40\uac15\ubbfc <https://github.com/gangsss>`_ , `\uae40\uc9c4\ud604 <https://github.com/lewhe0>`_\n\n\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c\ub294 ``torchtext`` \uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\ub294 \ud14d\uc2a4\ud2b8 \ubd84\ub958\n\ub370\uc774\ud130\uc14b\uc758 \uc0ac\uc6a9 \ubc29\ubc95\uc744 \uc0b4\ud3b4 \ubd05\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc740 \ub2e4\uc74c\uc744 \ud3ec\ud568\ud569\ub2c8\ub2e4.\n\n::\n\n   - AG_NEWS,\n   - SogouNews,\n   - DBpedia,\n   - YelpReviewPolarity,\n   - YelpReviewFull,\n   - YahooAnswers,\n   - AmazonReviewPolarity,\n   - AmazonReviewFull\n\n\uc774 \uc608\uc81c\uc5d0\uc11c\ub294 ``TextClassification`` \uc758 \ub370\uc774\ud130\uc14b\ub4e4 \uc911 \ud558\ub098\ub97c \uc774\uc6a9\ud574 \ubd84\ub958\ub97c \uc704\ud55c\n \uc9c0\ub3c4 \ud559\uc2b5 \uc54c\uace0\ub9ac\uc998\uc744 \ud6c8\ub828\ud558\ub294 \ubc29\ubc95\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\n\nngrams\ub97c \uc774\uc6a9\ud558\uc5ec \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n-----------------------------------\n\nBag of ngrams \ud53c\uccd0\ub294 \uc9c0\uc5ed(local) \ub2e8\uc5b4 \uc21c\uc11c\uc5d0 \ub300\ud55c \ubd80\ubd84\uc801\uc778 \uc815\ubcf4\ub97c \ud3ec\ucc29\ud558\uae30 \uc704\ud574 \uc801\uc6a9\ud569\ub2c8\ub2e4.\n\uc2e4\uc81c \uc0c1\ud669\uc5d0\uc11c\ub294 bi-gram\uc774\ub098 tri-gram\uc740 \ub2e8 \ud558\ub098\uc758 \ub2e8\uc5b4\ub97c \uc774\uc6a9\ud558\ub294 \uac83\ubcf4\ub2e4 \ub354 \ub9ce\uc740 \uc774\uc775\uc744 \uc8fc\uae30 \ub54c\ubb38\uc5d0 \uc801\uc6a9\ub429\ub2c8\ub2e4.\n\uc608\ub97c \ub4e4\uba74 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n\n::\n\n   \"load data with ngrams\"\n   Bi-grams \uacb0\uacfc: \"load data\", \"data with\", \"with ngrams\"\n   Tri-grams \uacb0\uacfc: \"load data with\", \"data with ngrams\"\n\n``TextClassification`` \ub370\uc774\ud130\uc14b\uc740 ngrams method\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4. ngrams\uc744 2\ub85c \uc124\uc815\ud558\uba74,\n\ub370\uc774\ud130\uc14b \uc548\uc758 \uc608\uc81c \ud14d\uc2a4\ud2b8\ub294 \uac01\uac01\uc758(single) \ub2e8\uc5b4\ub4e4\uc5d0 bi-grams \ubb38\uc790\uc5f4\uc774 \ub354\ud574\uc9c4 \ub9ac\uc2a4\ud2b8\uac00 \ub420 \uac83\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchtext\nfrom torchtext.datasets import text_classification\nNGRAMS = 2\nimport os\nif not os.path.isdir('./.data'):\n\tos.mkdir('./.data')\ntrain_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](\n    root='./.data', ngrams=NGRAMS, vocab=None)\nBATCH_SIZE = 16\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378 \uc815\uc758\ud558\uae30\n-------------\n\n\uc6b0\ub9ac\uc758 \ubaa8\ub378\uc740\n`EmbeddingBag <https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>`__\n\ub808\uc774\uc5b4\uc640 \uc120\ud615 \ub808\uc774\uc5b4\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4 (\uc544\ub798 \uadf8\ub9bc \ucc38\uace0).\n``nn.EmbeddingBag``\ub294 \uc784\ubca0\ub529\ub4e4\ub85c \uad6c\uc131\ub41c '\uac00\ubc29'\uc758 \ud3c9\uade0\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n\uc774\ub54c \ud14d\uc2a4\ud2b8(text)\uc758 \uac01 \uc6d0\uc18c\ub294 \uadf8 \uae38\uc774\uac00 \ub2e4\ub97c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud14d\uc2a4\ud2b8\uc758\n\uae38\uc774\ub294 \uc624\ud504\uc14b(offset)\uc5d0 \uc800\uc7a5\ub418\uc5b4 \uc788\uc73c\ubbc0\ub85c \uc5ec\uae30\uc11c ``nn.EmbeddingBag``\n\uc5d0 \ud328\ub529\uc744 \uc0ac\uc6a9\ud560 \ud544\uc694\ub294 \uc5c6\uc2b5\ub2c8\ub2e4.\n\n\ub367\ubd99\uc5ec\uc11c, ``nn.EmbeddingBag`` \uc740 \uc784\ubca0\ub529\uc758 \ud3c9\uade0\uc744 \uc989\uc2dc \uacc4\uc0b0\ud558\uae30 \ub54c\ubb38\uc5d0,\n\ud150\uc11c\ub4e4\uc758 \uc2dc\ud000\uc2a4\ub97c \ucc98\ub9ac\ud560 \ub54c \uc131\ub2a5 \ubc0f \uba54\ubaa8\ub9ac \ud6a8\uc728\uc131 \uce21\uba74\uc5d0\uc11c\uc758 \uc7a5\uc810\ub3c4\n\uac16\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\n![](../_static/img/text_sentiment_ngrams_model.png)\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch.nn.functional as F\nclass TextSentiment(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_class):\n        super().__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n        self.fc = nn.Linear(embed_dim, num_class)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.5\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.fc.weight.data.uniform_(-initrange, initrange)\n        self.fc.bias.data.zero_()\n\n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131\ud558\uae30\n-----------------\n\nAG_NEWS \ub370\uc774\ud130\uc14b\uc5d0\ub294 4 \uc885\ub958\uc758 \ub808\uc774\ube14\uc774 \ub2ec\ub824 \uc788\uc73c\uba70, \ub530\ub77c\uc11c \ud074\ub798\uc2a4\uc758 \uac1c\uc218\ub3c4 4\uac1c \uc785\ub2c8\ub2e4.\n\n::\n\n   1 : World (\uc138\uacc4)\n   2 : Sports (\uc2a4\ud3ec\uce20)\n   3 : Business (\uacbd\uc81c)\n   4 : Sci/Tec (\uacfc\ud559/\uae30\uc220)\n\n\uc5b4\ud718\uc9d1\uc758 \ud06c\uae30(Vocab size)\ub294 \uc5b4\ud718\uc9d1(vocab)\uc758 \uae38\uc774\uc640 \uac19\uc2b5\ub2c8\ub2e4 (\uc5ec\uae30\uc5d0\ub294\n\uac01\uac01\uc758 \ub2e8\uc5b4\uc640 ngrame\uc774 \ubaa8\ub450 \ud3ec\ud568\ub429\ub2c8\ub2e4). \ud074\ub798\uc2a4\uc758 \uac1c\uc218\ub294 \ub808\uc774\ube14\uc758 \uc885\ub958\n\uc218\uc640 \uac19\uc73c\uba70, AG_NEWS\uc758 \uacbd\uc6b0\uc5d0\ub294 4\uac1c \uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(train_dataset.get_vocab())\nEMBED_DIM = 32\nNUN_CLASS = len(train_dataset.get_labels())\nmodel = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubc30\uce58 \uc0dd\uc131\uc744 \uc704\ud55c \ud568\uc218\ub4e4\n-----------------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud14d\uc2a4\ud2b8 \uc6d0\uc18c\uc758 \uae38\uc774\uac00 \ub2e4\ub97c \uc218 \uc788\uc73c\ubbc0\ub85c, \ub370\uc774\ud130 \ubc30\uce58\uc640 \uc624\ud504\uc14b\uc744 \uc0dd\uc131\ud558\uae30\n\uc704\ud55c \uc0ac\uc6a9\uc790 \ud568\uc218 generate_batch()\ub97c \uc0ac\uc6a9\ud558\ub824 \ud569\ub2c8\ub2e4. \uc774 \ud568\uc218\ub294\n``torch.utils.data.DataLoader`` \uc758 ``collate_fn`` \uc778\uc790\ub85c \ub118\uaca8\uc90d\ub2c8\ub2e4.\n\n``collate_fn`` \uc758 \uc785\ub825\uc740 \uadf8 \ud06c\uae30\uac00 batch_size\uc778 \ud150\uc11c\ub4e4\uc758 \ub9ac\uc2a4\ud2b8\uc774\uba70,\n``collate_fn`` \uc740 \uc774\ub4e4\uc744 \ubbf8\ub2c8\ubc30\uce58\ub85c \ubb36\ub294 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4. \uc5ec\ub7ec\ubd84\uc774\n\uc8fc\uc758\ud574\uc57c \ud560 \uc810\uc740, ``collate_fn`` \ub97c \uc120\uc5b8\ud560 \ub54c \ucd5c\uc0c1\uc704 \ub808\ubca8\uc5d0\uc11c \uc815\uc758\ud574\uc57c\n\ud55c\ub2e4\ub294 \uc810\uc785\ub2c8\ub2e4. \uadf8\ub798\uc57c \uc774 \ud568\uc218\ub97c \uac01\uac01\uc758 \uc6cc\ucee4\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc74c\uc774\n\ubcf4\uc7a5\ub429\ub2c8\ub2e4.\n\n\uc6d0\ubcf8 \ub370\uc774\ud130 \ubc30\uce58 \uc785\ub825\uc758 \ud14d\uc2a4\ud2b8 \uc6d0\uc18c\ub4e4\uc740 \ub9ac\uc2a4\ud2b8 \ud615\ud0dc\uc774\uba70, \uc774\ub4e4\uc744 \ud558\ub098\uc758\n\ud150\uc11c\uac00 \ub418\ub3c4\ub85d \uc774\uc5b4 \ubd99\uc778 \uac83\uc774 ``nn.EmbeddingBag`` \uc758 \uc785\ub825\uc774 \ub429\ub2c8\ub2e4.\n\uc624\ud504\uc14b\uc740 \ud14d\uc2a4\ud2b8\uc758 \uacbd\uacc4\ub97c \ub098\ud0c0\ub0b4\ub294 \ud150\uc11c\uc774\uba70, \uac01 \uc6d0\uc18c\uac00 \ud14d\uc2a4\ud2b8 \ud150\uc11c\uc758\n\uc5b4\ub290 \uc778\ub371\uc2a4\uc5d0\uc11c \uc2dc\uc791\ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0c5\ub2c8\ub2e4. \ub808\uc774\ube14\uc740 \uac01 \ud14d\uc2a4\ud2b8 \uc6d0\uc18c\uc758\n\ub808\uc774\ube14\uc744 \ub2f4\uace0 \uc788\ub294 \ud150\uc11c\uc785\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_batch(batch):\n    label = torch.tensor([entry[0] for entry in batch])\n    text = [entry[1] for entry in batch]\n    offsets = [0] + [len(entry) for entry in text]\n    # torch.Tensor.cumsum\uc740 dim \ucc28\uc6d0\uc758 \uc694\uc18c\ub4e4\uc758 \ub204\uc801 \ud569\uacc4\ub97c \ubc18\ud658\ud569\ub2c8\ub2e4.\n    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text = torch.cat(text)\n    return text, offsets, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ubaa8\ub378\uc744 \ud559\uc2b5\ud558\uace0 \uacb0\uacfc\ub97c \ud3c9\uac00\ud558\ub294 \ud568\uc218 \uc815\uc758\ud558\uae30\n---------------------------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch \uc0ac\uc6a9\uc790\ub77c\uba74\n`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__\n\ub97c \ud65c\uc6a9\ud558\ub294 \uac83\uc744 \ucd94\ucc9c\ud569\ub2c8\ub2e4. \ub610\ud55c \uc774\ub97c \uc0ac\uc6a9\ud558\uba74 \ub370\uc774\ud130\ub97c \uc27d\uac8c \ubcd1\ub82c\uc801\uc73c\ub85c\n\uc77d\uc5b4\uc62c \uc218 \uc788\uc2b5\ub2c8\ub2e4 (\uc774\uc5d0 \ub300\ud55c \ud29c\ud1a0\ub9ac\uc5bc\uc740 `\uc774 \ubb38\uc11c <https://tutorials.pytorch.kr/beginner/data_loading_tutorial.html>`__\n\ub97c \ucc38\uace0\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4). \uc6b0\ub9ac\ub294 \uc5ec\uae30\uc11c ``DataLoader`` \ub97c \uc774\uc6a9\ud558\uc5ec\nAG_NEWS \ub370\uc774\ud130\uc14b\uc744 \uc77d\uc5b4\uc624\uace0, \uc774\ub97c \ubaa8\ub378\ub85c \ub118\uaca8 \ud559\uc2b5\uacfc \uac80\uc99d\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n\ndef train_func(sub_train_):\n\n    # Train the model\n    # \ubaa8\ub378\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4\n    train_loss = 0\n    train_acc = 0\n    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n                      collate_fn=generate_batch)\n    for i, (text, offsets, cls) in enumerate(data):\n        optimizer.zero_grad()\n        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n        output = model(text, offsets)\n        loss = criterion(output, cls)\n        train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        train_acc += (output.argmax(1) == cls).sum().item()\n\n    # \ud559\uc2b5\ub960\uc744 \uc870\uc808\ud569\ub2c8\ub2e4\n    scheduler.step()\n\n    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n\ndef test(data_):\n    loss = 0\n    acc = 0\n    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n    for text, offsets, cls in data:\n        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n        with torch.no_grad():\n            output = model(text, offsets)\n            loss = criterion(output, cls)\n            loss += loss.item()\n            acc += (output.argmax(1) == cls).sum().item()\n\n    return loss / len(data_), acc / len(data_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ub370\uc774\ud130\uc14b\uc744 \ubd84\ud560\ud558\uace0 \ubaa8\ub378 \uc218\ud589\ud558\uae30\n---------------------------------\n\n\uc6d0\ubcf8 AG_NEWS\uc5d0\ub294 \uac80\uc99d\uc6a9 \ub370\uc774\ud130\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0, \uc6b0\ub9ac\ub294 \ud559\uc2b5\n\ub370\uc774\ud130\ub97c \ud559\uc2b5 \ubc0f \uac80\uc99d \ub370\uc774\ud130\ub85c \ubd84\ud560\ud558\ub824 \ud569\ub2c8\ub2e4. \uc774\ub54c \ub370\uc774\ud130\ub97c \ubd84\ud560\ud558\ub294\n\ube44\uc728\uc740 0.95(\ud559\uc2b5)\uc640 0.05(\uac80\uc99d) \uc785\ub2c8\ub2e4. \uc6b0\ub9ac\ub294 \uc5ec\uae30\uc11c PyTorch\uc758\n\ud575\uc2ec \ub77c\uc774\ube0c\ub7ec\ub9ac \uc911 \ud558\ub098\uc778\n`torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>`__\n\ud568\uc218\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n`CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n\uae30\uc900(criterion)\uc740 \uac01 \ud074\ub798\uc2a4\uc5d0 \ub300\ud574 nn.LogSoftmax()\uc640 nn.NLLLoss()\ub97c\n\ud569\uccd0 \ub193\uc740 \ubc29\uc2dd\uc785\ub2c8\ub2e4.\n`SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>`__\noptimizer\ub294 \ud655\ub960\uc801 \uacbd\uc0ac \ud558\uac15\ubc95\ub97c \uad6c\ud604\ud574\ub193\uc740 \uac83\uc785\ub2c8\ub2e4. \ucc98\uc74c\uc758 \ud559\uc2b5\ub960\uc740\n4.0\uc73c\ub85c \ub450\uc5c8\uc2b5\ub2c8\ub2e4. \ub9e4 \uc5d0\ud3ed\uc744 \uc9c4\ud589\ud558\uba74\uc11c \ud559\uc2b5\ub960\uc744 \uc870\uc808\ud560 \ub54c\ub294\n`StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>`__\n\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nfrom torch.utils.data.dataset import random_split\nN_EPOCHS = 5\nmin_valid_loss = float('inf')\n\ncriterion = torch.nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=4.0)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n\ntrain_len = int(len(train_dataset) * 0.95)\nsub_train_, sub_valid_ = \\\n    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n    train_loss, train_acc = train_func(sub_train_)\n    valid_loss, valid_acc = test(sub_valid_)\n\n    secs = int(time.time() - start_time)\n    mins = secs / 60\n    secs = secs % 60\n\n    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ubaa8\ub378\uc744 GPU \uc0c1\uc5d0\uc11c \uc218\ud589\ud588\uc744 \ub54c \ub2e4\uc74c\uacfc \uac19\uc740 \uacb0\uacfc\ub97c \uc5bb\uc5c8\uc2b5\ub2c8\ub2e4.\n\nEpoch: 1 \\| time in 0 minutes, 11 seconds (\uc5d0\ud3ed 1, \uc218\ud589 \uc2dc\uac04 0\ubd84 11\ucd08)\n\n::\n\n       Loss: 0.0263(train)     |       Acc: 84.5%(train)\n       Loss: 0.0001(valid)     |       Acc: 89.0%(valid)\n\n\nEpoch: 2 \\| time in 0 minutes, 10 seconds (\uc5d0\ud3ed 2, \uc218\ud589 \uc2dc\uac04 0\ubd84 10\ucd08)\n\n::\n\n       Loss: 0.0119(train)     |       Acc: 93.6%(train)\n       Loss: 0.0000(valid)     |       Acc: 89.6%(valid)\n\n\nEpoch: 3 \\| time in 0 minutes, 9 seconds (\uc5d0\ud3ed 3, \uc218\ud589 \uc2dc\uac04 0\ubd84 9\ucd08)\n\n::\n\n       Loss: 0.0069(train)     |       Acc: 96.4%(train)\n       Loss: 0.0000(valid)     |       Acc: 90.5%(valid)\n\n\nEpoch: 4 \\| time in 0 minutes, 11 seconds (\uc5d0\ud3ed 4, \uc218\ud589 \uc2dc\uac04 0\ubd84 11\ucd08)\n\n::\n\n       Loss: 0.0038(train)     |       Acc: 98.2%(train)\n       Loss: 0.0000(valid)     |       Acc: 90.4%(valid)\n\n\nEpoch: 5 \\| time in 0 minutes, 11 seconds (\uc5d0\ud3ed 5, \uc218\ud589 \uc2dc\uac04 0\ubd84 11\ucd08)\n\n::\n\n       Loss: 0.0022(train)     |       Acc: 99.0%(train)\n       Loss: 0.0000(valid)     |       Acc: 91.0%(valid)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00 \ub370\uc774\ud130\ub85c \ubaa8\ub378 \ud3c9\uac00\ud558\uae30\n---------------------------\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Checking the results of test dataset...')\ntest_loss, test_acc = test(test_dataset)\nprint(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\ud3c9\uac00 \ub370\uc774\ud130\uc14b\uc744 \ud1b5\ud55c \uacb0\uacfc\ub97c \ud655\uc778\ud569\ub2c8\ub2e4...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#\n# ::\n#\n#        Loss: 0.0237(test)      |       Acc: 90.5%(test)\n#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc784\uc758\uc758 \ub274\uc2a4\ub85c \ud3c9\uac00\ud558\uae30\n----------------------\n\n\ud604\uc7ac\uae4c\uc9c0 \uad6c\ud55c \ucd5c\uace0\uc758 \ubaa8\ub378\ub85c \uace8\ud504 \ub274\uc2a4\ub97c \ud14c\uc2a4\ud2b8\ud574\ubcf4\ub824 \ud569\ub2c8\ub2e4. \ub808\uc774\ube14\uc5d0\n\ub300\ud55c \uc815\ubcf4\ub294\n`\uc5ec\uae30\uc5d0 <https://pytorch.org/text/datasets.html?highlight=ag_news#torchtext.datasets.AG_NEWS>`__\n\ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import re\nfrom torchtext.data.utils import ngrams_iterator\nfrom torchtext.data.utils import get_tokenizer\n\nag_news_label = {1 : \"World\",\n                 2 : \"Sports\",\n                 3 : \"Business\",\n                 4 : \"Sci/Tec\"}\n\ndef predict(text, model, vocab, ngrams):\n    tokenizer = get_tokenizer(\"basic_english\")\n    with torch.no_grad():\n        text = torch.tensor([vocab[token]\n                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n        output = model(text, torch.tensor([0]))\n        return output.argmax(1).item() + 1\n\nex_text_str = \"MEMPHIS, Tenn. \u2013 Four days ago, Jon Rahm was \\\n    enduring the season\u2019s worst weather conditions on Sunday at The \\\n    Open on his way to a closing 75 at Royal Portrush, which \\\n    considering the wind and the rain was a respectable showing. \\\n    Thursday\u2019s first round at the WGC-FedEx St. Jude Invitational \\\n    was another story. With temperatures in the mid-80s and hardly any \\\n    wind, the Spaniard was 13 strokes better in a flawless round. \\\n    Thanks to his best putting performance on the PGA Tour, Rahm \\\n    finished with an 8-under 62 for a three-stroke lead, which \\\n    was even more impressive considering he\u2019d never played the \\\n    front nine at TPC Southwind.\"\n\nvocab = train_dataset.get_vocab()\nmodel = model.to(\"cpu\")\n\nprint(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a Sports news (\uc2a4\ud3ec\uce20 \ub274\uc2a4)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\uc774 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ud55c \uc608\uc81c \ucf54\ub4dc\ub294\n`\uc5ec\uae30\uc5d0\uc11c <https://github.com/pytorch/text/tree/master/examples/text_classification>`__\n\ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}