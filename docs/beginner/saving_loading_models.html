


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>모델 저장하기 &amp; 불러오기 &mdash; PyTorch Tutorials 1.6.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<body class="pytorch-body">
  <nav class="navbar sticky-top navbar-dark fixed-top navbar-expand-lg" style="background: rgba(55,55,55,.8)">
    <div class="container-fluid">
      <div class="navbar-brand">
        <a href="https://pytorch.kr/" aria-label="PyTorch">
          <img src="../_static/images/logo-kr.svg" width="260" height="28" fill="white" />
        </a>
      </div>
      <button type="button" aria-label="Toggle navigation" class="navbar-toggler collapsed" aria-expanded="false" aria-controls="nav-collapse"><span class="navbar-toggler-icon"></span></button>
      <div id="nav-collapse" class="navbar-collapse collapse">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a href="//pytorch.kr/" target="_self" class="nav-link">홈</a></li>
          <li class="nav-item">
            <a href="//tutorials.pytorch.kr/" target="_self" class="nav-link">튜토리얼</a>
          </li>
          <li class="nav-item">
            <a href="//pytorch.kr/about" target="_self" class="nav-link">
              소개
            </a></li>
        </ul>
      </div>
    </div>
  </nav>

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.6.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">파이토치(PyTorch) 레시피</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">모든 레시피 보기</a></li>
</ul>
<p class="caption"><span class="caption-text">파이토치(PyTorch) 배우기</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">파이토치(PyTorch)로 딥러닝하기: 60분만에 끝장내기</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">예제로 배우는 파이토치(PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html"><cite>torch.nn</cite> 이 <em>실제로</em> 무엇인가요?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">TensorBoard로 모델, 데이터, 학습 시각화하기</a></li>
</ul>
<p class="caption"><span class="caption-text">이미지/비디오</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision 객체 검출 미세조정(Finetuning) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">컴퓨터 비전(Vision)을 위한 전이학습(Transfer Learning)</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">적대적 예제 생성(Adversarial Example Generation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">오디오</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_preprocessing_tutorial.html">torchaudio Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">텍스트</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="transformer_tutorial.html">nn.Transformer 와 TorchText 로 시퀀스-투-시퀀스(Sequence-to-Sequence) 모델링하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">기초부터 시작하는 NLP:  문자-단위 RNN으로 이름 생성하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">기초부터 시작하는 NLP: Sequence to Sequence 네트워크와 Attention을 이용한 번역</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">TorchText로 텍스트 분류하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_translation_tutorial.html">TorchText로 언어 번역하기</a></li>
</ul>
<p class="caption"><span class="caption-text">강화학습</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">강화 학습 (DQN) 튜토리얼</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch 모델을 프로덕션 환경에 배포하기</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Flask를 이용하여 Python에서 PyTorch를 REST API로 배포하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">TorchScript 소개</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">C++에서 TorchScript 모델 로딩하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(선택) PyTorch 모델을 ONNX으로 변환하고 ONNX 런타임에서 실행하기</a></li>
</ul>
<p class="caption"><span class="caption-text">프론트엔드 API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/named_tensor_tutorial.html">(prototype) Introduction to Named Tensors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Dispatcher in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">모델 최적화</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">가지치기 기법(Pruning) 튜토리얼</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(베타) BERT 모델 동적 양자화하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) 컴퓨터 비전(Vision) 튜토리얼을 위한 양자화된 전이학습(Quantized Transfer Learning)</a></li>
</ul>
<p class="caption"><span class="caption-text">병렬 및 분산 학습</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">단일 머신을 이용한 모델 병렬화 실습 예제</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">PyTorch로 분산 어플리케이션 개발하기</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="aws_distributed_training_tutorial.html">(advanced) PyTorch 1.0 Distributed Trainer with Amazon AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>모델 저장하기 &amp; 불러오기</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/beginner/saving_loading_models.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">beginner/saving_loading_models</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-beginner-saving-loading-models-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="sphx-glr-beginner-saving-loading-models-py">
<span id="id1"></span><h1>모델 저장하기 &amp; 불러오기<a class="headerlink" href="#sphx-glr-beginner-saving-loading-models-py" title="Permalink to this headline">¶</a></h1>
<dl class="simple">
<dt><strong>Author:</strong> <a class="reference external" href="https://github.com/MatthewInkawhich">Matthew Inkawhich</a></dt><dd><p><strong>번역</strong>: <a class="reference external" href="http://github.com/9bow">박정환</a></p>
</dd>
</dl>
<p>이 문서에서는 PyTorch 모델을 저장하고 불러오는 다양한 방법을 제공합니다.
이 문서 전체를 다 읽는 것도 좋은 방법이지만, 필요한 사용 예의 코드만 참고하는
것도 고려해보세요.</p>
<p>모델을 저장하거나 불러올 때는 3가지의 핵심 함수와 익숙해질 필요가 있습니다:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save">torch.save</a>:
직렬화된 객체를 디스크에 저장합니다. 이 함수는 Python의
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> 을 사용하여 직렬화합니다
이 함수를 사용하여 모든 종류의 객체의 모델, Tensor 및 사전을 저장할 수 있습니다.</p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=torch%20load#torch.load">torch.load</a>:
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a>을 사용하여
저장된 객체 파일들을 역직렬화하여 메모리에 올립니다. 이 함수는 데이터를 장치에
불러올 때도 사용합니다.
(<a class="reference external" href="#device">장치간 모델 저장하기 &amp; 불러오기</a> 참고)</p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/nn.html?highlight=load_state_dict#torch.nn.Module.load_state_dict">torch.nn.Module.load_state_dict</a>:
역직렬화된 <em>state_dict</em> 를 사용하여 모델의 매개변수들을 불러옵니다.
<em>state_dict</em> 에 대한 더 자세한 정보는 <a class="reference external" href="#state-dict">state_dict가 무엇인가요?</a> 를 참고하세요.</p></li>
</ol>
<p><strong>목차:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="#state-dict">state_dict가 무엇인가요?</a></p></li>
<li><p><a class="reference external" href="#inference">추론(inference)를 위해 모델 저장하기 &amp; 불러오기</a></p></li>
<li><p><a class="reference external" href="#checkpoint">일반 체크포인트(checkpoint) 저장하기 &amp; 불러오기</a></p></li>
<li><p><a class="reference external" href="#multiple">여러개(multiple)의 모델을 하나의 파일에 저장하기</a></p></li>
<li><p><a class="reference external" href="#warmstart">다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)</a></p></li>
<li><p><a class="reference external" href="#device">장치(device)간 모델 저장하기 &amp; 불러오기</a></p></li>
</ul>
<div class="section" id="state-dict">
<h2><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 가 무엇인가요?<a class="headerlink" href="#state-dict" title="Permalink to this headline">¶</a></h2>
<p>PyTorch에서 <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 모델의 학습 가능한 매개변수(예. 가중치와 편향)들은
모델의 매개변수에 포함되어 있습니다(model.parameters()로 접근합니다).
<em>state_dict</em> 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict)
객체입니다. 이 때, 학습 가능한 매개변수를 갖는 계층(합성곱 계층, 선형 계층 등)
및 등록된 버퍼들(batchnorm의 running_mean)만이 모델의 <em>state_dict</em> 에 항목을
가짐을 유의하시기 바랍니다. 옵티마이저 객체(<code class="docutils literal notranslate"><span class="pre">torch.optim</span></code>) 또한 옵티마이저의
상태 뿐만 아니라 사용된 하이퍼 매개변수(Hyperparameter) 정보가 포함된
<em>state_dict</em> 를 갖습니다.</p>
<p><em>state_dict</em> 객체는 Python 사전이기 때문에 쉽게 저장하거나 갱신하거나 바꾸거나
되살릴 수 있으며, PyTorch 모델과 옵티마이저에 엄청난 모듈성(modularity)을 제공합니다.</p>
<div class="section" id="id3">
<h3>예제:<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="blitz/cifar10_tutorial.html"><span class="doc">분류기(Classifier) 학습하기</span></a> 튜토리얼에서 사용한 간단한 모델의
<em>state_dict</em> 를 살펴보도록 하겠습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 모델 정의</span>
<span class="k">class</span> <span class="nc">TheModelClass</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TheModelClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># 모델 초기화</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">()</span>

<span class="c1"># 옵티마이저 초기화</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># 모델의 state_dict 출력</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Model&#39;s state_dict:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param_tensor</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">param_tensor</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">param_tensor</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># 옵티마이저의 state_dict 출력</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Optimizer&#39;s state_dict:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">var_name</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">var_name</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>출력:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span><span class="s1">&#39;s state_dict:</span>
<span class="n">conv1</span><span class="o">.</span><span class="n">weight</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">conv1</span><span class="o">.</span><span class="n">bias</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">6</span><span class="p">])</span>
<span class="n">conv2</span><span class="o">.</span><span class="n">weight</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">conv2</span><span class="o">.</span><span class="n">bias</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">16</span><span class="p">])</span>
<span class="n">fc1</span><span class="o">.</span><span class="n">weight</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">120</span><span class="p">,</span> <span class="mi">400</span><span class="p">])</span>
<span class="n">fc1</span><span class="o">.</span><span class="n">bias</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">120</span><span class="p">])</span>
<span class="n">fc2</span><span class="o">.</span><span class="n">weight</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">84</span><span class="p">,</span> <span class="mi">120</span><span class="p">])</span>
<span class="n">fc2</span><span class="o">.</span><span class="n">bias</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">84</span><span class="p">])</span>
<span class="n">fc3</span><span class="o">.</span><span class="n">weight</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">84</span><span class="p">])</span>
<span class="n">fc3</span><span class="o">.</span><span class="n">bias</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>

<span class="n">Optimizer</span><span class="s1">&#39;s state_dict:</span>
<span class="n">state</span>    <span class="p">{}</span>
<span class="n">param_groups</span>     <span class="p">[{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;momentum&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s1">&#39;dampening&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;nesterov&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4675713712</span><span class="p">,</span> <span class="mi">4675713784</span><span class="p">,</span> <span class="mi">4675714000</span><span class="p">,</span> <span class="mi">4675714072</span><span class="p">,</span> <span class="mi">4675714216</span><span class="p">,</span> <span class="mi">4675714288</span><span class="p">,</span> <span class="mi">4675714432</span><span class="p">,</span> <span class="mi">4675714504</span><span class="p">,</span> <span class="mi">4675714648</span><span class="p">,</span> <span class="mi">4675714720</span><span class="p">]}]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="inference">
<h2>추론(inference)를 위해 모델 저장하기 &amp; 불러오기<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id4">
<h3><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 저장하기 / 불러오기 (권장)<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PyTorch 버전 1.6에서는 새로운 Zip파일-기반의 파일 포맷을 사용하도록
<code class="docutils literal notranslate"><span class="pre">torch.save</span></code> 가 변경되었습니다. <code class="docutils literal notranslate"><span class="pre">torch.load</span></code> 는 예전 방식의 파일들을
읽어올 수 있도록 하고 있습니다. 어떤 이유에서든 <code class="docutils literal notranslate"><span class="pre">torch.save</span></code> 가 예전
방식을 사용하도록 하고 싶다면, <code class="docutils literal notranslate"><span class="pre">_use_new_zipfile_serialization=False</span></code> 을
kwarg로 전달하세요.</p>
</div>
<p>추론을 위해 모델을 저장할 때는 학습된 모델의 학습된 매개변수만 저장하면 됩니다.
<code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> 를 사용하여 모델의 <em>state_dict</em> 를 저장하는 것이 나중에 모델을
사용할 때 가장 유연하게 사용할 수 있는, 모델 저장 시 권장하는 방법입니다.</p>
<p>PyTorch에서는 모델을 저장할 때 <code class="docutils literal notranslate"><span class="pre">.pt</span></code> 또는 <code class="docutils literal notranslate"><span class="pre">.pth</span></code> 확장자를 사용하는 것이
일반적인 규칙입니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code> 함수에는 저장된 객체의 경로가 아닌, 사전 객체를
전달해야 하는 것에 유의하세요. 따라서 저장된 <em>state_dict</em> 를 <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code>
함수에 전달하기 전에 반드시 역직렬화를 해야 합니다. 예를 들어,
<code class="docutils literal notranslate"><span class="pre">model.load_state_dict(PATH)</span></code> 과 같은 식으로는 사용하면 안됩니다.</p>
</div>
</div>
<div class="section" id="id5">
<h3>전체 모델 저장하기/불러오기<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 모델 클래스는 어딘가에 반드시 선언되어 있어야 합니다</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p>이 저장하기/불러오기 과정은 가장 직관적인 문법을 사용하며 적은 양의
코드를 사용합니다. 이러한 방식으로 모델을 저장하는 것은 Python의
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> 모듈을 사용하여
전체 모듈을 저장하게 됩니다. 하지만 pickle은 모델 그 자체를 저장하지 않기 때문에
직렬화된 데이터가 모델을 저장할 때 사용한 특정 클래스 및 디렉토리 경로(구조)에
얽매인다는 것이 이 방식의 단점입니다. 대신에 클래스가 위치한 파일의 경로를
저장해두고, 불러오는 시점에 사용합니다. 이러한 이유 때문에, 만들어둔 코드를
다른 프로젝트에서 사용하거나 리팩토링 후에 다양한 이유로 동작하지 않을 수
있습니다.</p>
<p>PyTorch에서는 모델을 저장할 때 <code class="docutils literal notranslate"><span class="pre">.pt</span></code> 또는 <code class="docutils literal notranslate"><span class="pre">.pth</span></code> 확장자를 사용하는 것이
일반적인 규칙입니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다.</p>
</div>
</div>
<div class="section" id="checkpoint">
<h2>추론 / 학습 재개를 위해 일반 체크포인트(checkpoint) 저장하기 &amp; 불러오기<a class="headerlink" href="#checkpoint" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id6">
<h3>저장하기:<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="o">...</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h3>불러오기:<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">TheOptimizerClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># - or -</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>추론 또는 학습 재개를 위해 일반 체크포인트를 저장할 때는 반드시 모델의
<em>state_dict</em> 보다 많은 것들을 저장해야 합니다. 모델이 학습을 하며 갱신되는
버퍼와 매개변수가 포함된 옵티마이저의 <em>state_dict</em> 도 함께 저장하는 것이
중요합니다. 그 외에도 마지막 에폭(epoch), 최근에 기록된 학습 손실, 외부
<code class="docutils literal notranslate"><span class="pre">torch.nn.Embedding</span></code> 계층 등도 함께 저장합니다.</p>
<p>여러가지를 함께 저장하려면, 사전(dictionary) 자료형으로 만든 후
<code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> 를 사용하여 직렬화합니다. PyTorch가 이러한 체크포인트를 저장할
때는 <code class="docutils literal notranslate"><span class="pre">.tar</span></code> 확장자를 사용하는 것이 일반적인 규칙입니다.</p>
<p>항목들을 불러올 때에는 먼저 모델과 옵티마이저를 초기화한 후, <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code>
를 사용하여 사전을 불러옵니다. 이후로는 저장된 항목들을 사전에 원하는대로 사전에
질의하여 쉽게 접근할 수 있습니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다. 만약 학습을 계속하고 싶다면, <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> 을 호출하여
학습 모드로 전환되도록 해야 합니다.</p>
</div>
</div>
<div class="section" id="multiple">
<h2>여러개(multiple)의 모델을 하나의 파일에 저장하기<a class="headerlink" href="#multiple" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3>저장하기:<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">&#39;modelA_state_dict&#39;</span><span class="p">:</span> <span class="n">modelA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;modelB_state_dict&#39;</span><span class="p">:</span> <span class="n">modelB</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizerA_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizerA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizerB_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizerB</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="o">...</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h3>불러오기:<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">modelA</span> <span class="o">=</span> <span class="n">TheModelAClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">modelB</span> <span class="o">=</span> <span class="n">TheModelBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizerA</span> <span class="o">=</span> <span class="n">TheOptimizerAClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizerB</span> <span class="o">=</span> <span class="n">TheOptimizerBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">modelA</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;modelA_state_dict&#39;</span><span class="p">])</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;modelB_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizerA</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizerA_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizerB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizerB_state_dict&#39;</span><span class="p">])</span>

<span class="n">modelA</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># - or -</span>
<span class="n">modelA</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>GAN, Seq2Seq 또는 앙상블 모델과 같이 여러개의 여러개의 <code class="docutils literal notranslate"><span class="pre">torch.nn.Modules</span></code> 로
구성된 모델을 저장하는 경우에는 일반 체크포인트를 저장할 때와 같은 방식을
따릅니다. 즉, 각 모델의 <em>state_dict</em> 와 해당 옵티마이저를 사전으로 저장합니다.
앞에서 언급했던 것과 같이, 학습을 재개하는데 필요한 다른 항목들을 사전에 추가하여
저장할 수 있습니다.</p>
<p>PyTorch가 이러한 체크포인트를 저장할 때는 <code class="docutils literal notranslate"><span class="pre">.tar</span></code> 확장자를 사용하는 것이
일반적인 규칙입니다.</p>
<p>항목들을 불러올 때에는 먼저 모델과 옵티마이저를 초기화한 후, <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code>
를 사용하여 사전을 불러옵니다. 이후로는 저장된 항목들을 사전에 원하는대로 사전에
질의하여 쉽게 접근할 수 있습니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다. 만약 학습을 계속하고 싶다면, <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> 을 호출하여
학습 모드로 설정해야 합니다.</p>
</div>
</div>
<div class="section" id="warmstart">
<h2>다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)<a class="headerlink" href="#warmstart" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id10">
<h3>저장하기:<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">modelA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id11">
<h3>불러오기:<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">modelB</span> <span class="o">=</span> <span class="n">TheModelBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<p>부분적으로 모델을 불러오거나, 모델의 일부를 불러오는 것은 전이학습 또는
새로운 복잡한 모델을 학습할 때 일반적인 시나리오입니다. 학습된 매개변수를
사용하면, 일부만 사용한다 하더라도 학습 과정을 빠르게 시작할 수 있고,
처음부터 시작하는 것보다 훨씬 빠르게 모델이 수렴하도록 도울 것입니다.</p>
<p>몇몇 키를 제외하고 <em>state_dict</em> 의 일부를 불러오거나, 적재하려는 모델보다
더 많은 키를 갖고 있는 <em>state_dict</em> 를 불러올 때에는 <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code>
함수에서 <code class="docutils literal notranslate"><span class="pre">strict</span></code> 인자를 <strong>False</strong> 로 설정하여 일치하지 않는 키들을
무시하도록 해야 합니다.</p>
<p>한 계층에서 다른 계층으로 매개변수를 불러오고 싶지만, 일부 키가 일치하지
않을 때에는 적재하려는 모델의 키와 일치하도록 <em>state_dict</em> 의 매개변수 키의
이름을 변경하면 됩니다.</p>
</div>
</div>
<div class="section" id="device">
<h2>장치(device)간 모델 저장하기 &amp; 불러오기<a class="headerlink" href="#device" title="Permalink to this headline">¶</a></h2>
<div class="section" id="gpu-cpu">
<h3>GPU에서 저장하고 CPU에서 불러오기<a class="headerlink" href="#gpu-cpu" title="Permalink to this headline">¶</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
<p>GPU에서 학습한 모델을 CPU에서 불러올 때는 <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code> 함수의
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> 인자에 <code class="docutils literal notranslate"><span class="pre">torch.device('cpu')</span></code> 을 전달합니다.
이 경우에는 Tensor에 저장된 내용들은 <code class="docutils literal notranslate"><span class="pre">map_location</span></code> 인자를 사용하여 CPU 장치에
동적으로 재배치됩니다.</p>
</div>
<div class="section" id="gpu-gpu">
<h3>GPU에서 저장하고 GPU에서 불러오기<a class="headerlink" href="#gpu-gpu" title="Permalink to this headline">¶</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 모델에서 사용하는 input Tensor들은 input = input.to(device) 을 호출해야 합니다.</span>
</pre></div>
</div>
<p>GPU에서 학습한 모델을 GPU에서 불러올 때에는, 초기화된 <code class="docutils literal notranslate"><span class="pre">model</span></code> 에
<code class="docutils literal notranslate"><span class="pre">model.to(torch.device('cuda'))</span></code> 을 호출하여 CUDA 최적화된 모델로 변환해야
합니다. 또한, 모델에 데이터를 제공하는 모든 입력에 <code class="docutils literal notranslate"><span class="pre">.to(torch.device('cuda'))</span></code>
함수를 호출해야 합니다. <code class="docutils literal notranslate"><span class="pre">my_tensor.to(device)</span></code> 를 호출하면 GPU에 <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code>
의 복사본을 반환하기 때문에, Tensor를 직접 덮어써야 합니다:
<code class="docutils literal notranslate"><span class="pre">my_tensor</span> <span class="pre">=</span> <span class="pre">my_tensor.to(torch.device('cuda'))</span></code> .</p>
</div>
<div class="section" id="cpu-gpu">
<h3>CPU에서 저장하고 GPU에서 불러오기<a class="headerlink" href="#cpu-gpu" title="Permalink to this headline">¶</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">))</span>  <span class="c1"># 사용할 GPU 장치 번호를 선택합니다.</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 모델에서 사용하는 input Tensor들은 input = input.to(device) 을 호출해야 합니다.</span>
</pre></div>
</div>
<p>CPU에서 학습한 모델을 GPU에서 불러올 때는 <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code> 함수의
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> 인자에 <em>cuda:device_id</em> 을 설정합니다. 이렇게 하면 모델이 해당
GPU 장치에 불러와집니다. 다음으로 <code class="docutils literal notranslate"><span class="pre">model.to(torch.device('cuda'))</span></code> 을 호출하여
모델의 매개변수 Tensor들을 CUDA Tensor들로 변환해야 합니다. 마지막으로 모든
모델 입력에 <code class="docutils literal notranslate"><span class="pre">.to(torch.device('cuda'))</span></code> 을 사용하여 CUDA 최적화된 모델을 위한
데이터로 만들어야 합니다. <code class="docutils literal notranslate"><span class="pre">my_tensor.to(device)</span></code> 를 호출하면 GPU에 <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code>
의 복사본을 반환합니다. 이 동작은 <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code> 를 덮어쓰지 않기 때문에, Tensor를
직접 덮어써야 합니다: <code class="docutils literal notranslate"><span class="pre">my_tensor</span> <span class="pre">=</span> <span class="pre">my_tensor.to(torch.device('cuda'))</span></code> .</p>
</div>
<div class="section" id="torch-nn-dataparallel">
<h3><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> 모델 저장하기<a class="headerlink" href="#torch-nn-dataparallel" title="Permalink to this headline">¶</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 사용할 장치에 불러옵니다.</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> 은 병렬 GPU 활용을 가능하게 하는 모델 래퍼(wrapper)입니다.
<code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> 모델을 범용적으로 저장하려면 <code class="docutils literal notranslate"><span class="pre">model.module.state_dict()</span></code> 을
사용하면 됩니다. 이렇게 하면 원하는 모든 장치에 원하는 방식으로 유연하게 모델을
불러올 수 있습니다.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-saving-loading-models-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7d5771891cc8e2f733352e4fc8fc63b6/saving_loading_models.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">saving_loading_models.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e139fbbcadcc4d83aab8995db4b9147c/saving_loading_models.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">saving_loading_models.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  

  

    <hr class="helpful-hr hr-top">
      <div class="helpful-container">
        <div class="helpful-question">이 문서가 도움이 되었나요?</div>
        <div class="helpful-question yes-link" data-behavior="was-this-helpful-event" data-response="yes">네</div>
        <div class="helpful-question no-link" data-behavior="was-this-helpful-event" data-response="no">아니오</div>
        <div class="was-helpful-thank-you">피드백을 주셔서 감사합니다.</div>
      </div>
    <hr class="helpful-hr hr-bottom"/>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, PyTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">모델 저장하기 &amp; 불러오기</a><ul>
<li><a class="reference internal" href="#state-dict"><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 가 무엇인가요?</a><ul>
<li><a class="reference internal" href="#id3">예제:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#inference">추론(inference)를 위해 모델 저장하기 &amp; 불러오기</a><ul>
<li><a class="reference internal" href="#id4"><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 저장하기 / 불러오기 (권장)</a></li>
<li><a class="reference internal" href="#id5">전체 모델 저장하기/불러오기</a></li>
</ul>
</li>
<li><a class="reference internal" href="#checkpoint">추론 / 학습 재개를 위해 일반 체크포인트(checkpoint) 저장하기 &amp; 불러오기</a><ul>
<li><a class="reference internal" href="#id6">저장하기:</a></li>
<li><a class="reference internal" href="#id7">불러오기:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiple">여러개(multiple)의 모델을 하나의 파일에 저장하기</a><ul>
<li><a class="reference internal" href="#id8">저장하기:</a></li>
<li><a class="reference internal" href="#id9">불러오기:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#warmstart">다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)</a><ul>
<li><a class="reference internal" href="#id10">저장하기:</a></li>
<li><a class="reference internal" href="#id11">불러오기:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#device">장치(device)간 모델 저장하기 &amp; 불러오기</a><ul>
<li><a class="reference internal" href="#gpu-cpu">GPU에서 저장하고 CPU에서 불러오기</a></li>
<li><a class="reference internal" href="#gpu-gpu">GPU에서 저장하고 GPU에서 불러오기</a></li>
<li><a class="reference internal" href="#cpu-gpu">CPU에서 저장하고 GPU에서 불러오기</a></li>
<li><a class="reference internal" href="#torch-nn-dataparallel"><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> 모델 저장하기</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../_static/jquery.js"></script>
         <script type="text/javascript" src="../_static/underscore.js"></script>
         <script type="text/javascript" src="../_static/doctools.js"></script>
         <script type="text/javascript" src="../_static/language_data.js"></script>
         <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-71919972-3', 'auto');
  ga('send', 'pageview');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="footer-container container">
      <div class="footer-logo-wrapper"><a href="https://pytorch.kr" class="footer-logo"></a></div>
      <div class="footer-links-wrapper pb-2">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org">PyTorch 홈페이지 (공식)</a></li>
            <li><a href="https://pytorch.org">공식 홈페이지</a></li>
            <li><a href="https://pytorch.org/tutorials">공식 튜토리얼</a></li>
            <li><a href="https://pytorch.org/docs">공식 문서</a></li>
          </ul>
        </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.kr">한국어 홈페이지 (비공식)</a></li>
            <li><a href="https://pytorch.kr/about" class="">사이트 소개</a></li>
            <li><a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a></li>
            <li><a href="https://github.com/9bow/PyTorch-tutorials-kr" target="_blank">한국어 튜토리얼 저장소</a></li>
          </ul>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>